{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitdate</th>\n",
       "      <th>lastpage</th>\n",
       "      <th>startlanguage</th>\n",
       "      <th>seed</th>\n",
       "      <th>startdate</th>\n",
       "      <th>datestamp</th>\n",
       "      <th>sequence1</th>\n",
       "      <th>seqOne</th>\n",
       "      <th>Dep5words[Word1]</th>\n",
       "      <th>...</th>\n",
       "      <th>wor_all_selected</th>\n",
       "      <th>wor_all_selected1</th>\n",
       "      <th>minidep_scale</th>\n",
       "      <th>minidep_diagnose</th>\n",
       "      <th>depression_episodes</th>\n",
       "      <th>miniGAD_scale</th>\n",
       "      <th>miniGAD_symptoms_scale</th>\n",
       "      <th>miniGAD_diagnose</th>\n",
       "      <th>minidiagnose_category</th>\n",
       "      <th>minidiagnose_category_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434.0</td>\n",
       "      <td>2020-08-07 11:46:22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>6.593644e+08</td>\n",
       "      <td>2020-08-07 11:38:22</td>\n",
       "      <td>2020-08-07 11:46:22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motivated</td>\n",
       "      <td>...</td>\n",
       "      <td>NA NA happy NA NA NA NA NA NA NA NA NA NA care...</td>\n",
       "      <td>happy           carefree     satisfied      ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184.0</td>\n",
       "      <td>2020-08-07 11:58:36</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>2.803892e+08</td>\n",
       "      <td>2020-08-07 11:34:31</td>\n",
       "      <td>2020-08-07 11:58:36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>connected</td>\n",
       "      <td>...</td>\n",
       "      <td>anxious NA NA NA NA NA NA NA NA NA NA tense NA...</td>\n",
       "      <td>anxious           tense    fearful  sad     fe...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330.0</td>\n",
       "      <td>2020-08-07 11:51:54</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>6.770686e+07</td>\n",
       "      <td>2020-08-07 11:36:32</td>\n",
       "      <td>2020-08-07 11:51:54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>anxious NA NA NA NA NA worried NA NA NA NA NA ...</td>\n",
       "      <td>anxious      worried      scared     sad   mon...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630.0</td>\n",
       "      <td>2020-08-07 13:22:42</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.176643e+09</td>\n",
       "      <td>2020-08-07 12:55:26</td>\n",
       "      <td>2020-08-07 13:22:42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>minor</td>\n",
       "      <td>...</td>\n",
       "      <td>anxious NA NA NA NA concerned NA NA NA NA NA t...</td>\n",
       "      <td>anxious     concerned      tense scared       ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400.0</td>\n",
       "      <td>2020-08-07 12:04:52</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.012492e+09</td>\n",
       "      <td>2020-08-07 11:37:19</td>\n",
       "      <td>2020-08-07 12:04:52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>family</td>\n",
       "      <td>...</td>\n",
       "      <td>NA NA NA NA NA concerned NA NA NA NA NA tense ...</td>\n",
       "      <td>concerned      tense      sad      tired ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>GAD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id           submitdate  lastpage startlanguage          seed  \\\n",
       "0  434.0  2020-08-07 11:46:22      15.0            en  6.593644e+08   \n",
       "1  184.0  2020-08-07 11:58:36      15.0            en  2.803892e+08   \n",
       "2  330.0  2020-08-07 11:51:54      15.0            en  6.770686e+07   \n",
       "3  630.0  2020-08-07 13:22:42      15.0            en  1.176643e+09   \n",
       "4  400.0  2020-08-07 12:04:52      15.0            en  1.012492e+09   \n",
       "\n",
       "             startdate            datestamp  sequence1  seqOne  \\\n",
       "0  2020-08-07 11:38:22  2020-08-07 11:46:22        2.0     1.0   \n",
       "1  2020-08-07 11:34:31  2020-08-07 11:58:36        2.0     1.0   \n",
       "2  2020-08-07 11:36:32  2020-08-07 11:51:54        1.0     1.0   \n",
       "3  2020-08-07 12:55:26  2020-08-07 13:22:42        3.0     1.0   \n",
       "4  2020-08-07 11:37:19  2020-08-07 12:04:52        1.0     1.0   \n",
       "\n",
       "  Dep5words[Word1]  ...                                   wor_all_selected  \\\n",
       "0        motivated  ...  NA NA happy NA NA NA NA NA NA NA NA NA NA care...   \n",
       "1        connected  ...  anxious NA NA NA NA NA NA NA NA NA NA tense NA...   \n",
       "2              Yes  ...  anxious NA NA NA NA NA worried NA NA NA NA NA ...   \n",
       "3            minor  ...  anxious NA NA NA NA concerned NA NA NA NA NA t...   \n",
       "4           family  ...  NA NA NA NA NA concerned NA NA NA NA NA tense ...   \n",
       "\n",
       "                                   wor_all_selected1 minidep_scale  \\\n",
       "0    happy           carefree     satisfied      ...           0.0   \n",
       "1  anxious           tense    fearful  sad     fe...           3.0   \n",
       "2  anxious      worried      scared     sad   mon...           7.0   \n",
       "3  anxious     concerned      tense scared       ...           3.0   \n",
       "4       concerned      tense      sad      tired ...           4.0   \n",
       "\n",
       "  minidep_diagnose depression_episodes miniGAD_scale miniGAD_symptoms_scale  \\\n",
       "0                0                   0             0                      0   \n",
       "1                0                   0             8                      5   \n",
       "2                0                   5             9                      5   \n",
       "3                0                   5             8                      5   \n",
       "4                0                   2             7                      4   \n",
       "\n",
       "  miniGAD_diagnose minidiagnose_category  minidiagnose_category_number  \n",
       "0                0                  NoDi                             0  \n",
       "1                0                  NoDi                             0  \n",
       "2                0                  NoDi                             0  \n",
       "3                0                  NoDi                             0  \n",
       "4                1                   GAD                             2  \n",
       "\n",
       "[5 rows x 407 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "responses = pd.read_csv('data/response_format_cleaned_ds1.csv', sep=';', header=0)\n",
    "responses.drop(responses.columns[[0]], axis=1, inplace=True)\n",
    "responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id -> 434.0\n",
      "submitdate -> 2020-08-07 11:46:22\n",
      "lastpage -> 15.0\n",
      "startlanguage -> en\n",
      "seed -> 659364415.0\n",
      "startdate -> 2020-08-07 11:38:22\n",
      "datestamp -> 2020-08-07 11:46:22\n",
      "sequence1 -> 2.0\n",
      "seqOne -> 1.0\n",
      "Dep5words[Word1] -> motivated\n",
      "Dep5words[Word2] -> learning\n",
      "Dep5words[Word3] -> passionate\n",
      "Dep5words[Word4] -> enthusiastic\n",
      "Dep5words[Word5] -> happy\n",
      "Wor5words[SQ01] -> motivated\n",
      "Wor5words[SQ02] -> enthusiastic\n",
      "Wor5words[SQ03] -> learning\n",
      "Wor5words[SQ04] -> exercise\n",
      "Wor5words[SQ05] -> nutrition\n",
      "sequence2 -> 3.0\n",
      "seq2 -> 2.0\n",
      "Dep5phraseorwords[SQ01] -> happy\n",
      "Dep5phraseorwords[SQ02] -> eager to learn\n",
      "Dep5phraseorwords[SQ03] -> restful sleep\n",
      "Dep5phraseorwords[SQ04] -> motivated\n",
      "Dep5phraseorwords[SQ05] -> joyful\n",
      "Wor5phraseorwords[SQ01] -> content\n",
      "Wor5phraseorwords[SQ02] -> improving\n",
      "Wor5phraseorwords[SQ03] -> learning\n",
      "Wor5phraseorwords[SQ04] -> motivated\n",
      "Wor5phraseorwords[SQ05] -> better than before\n",
      "sequence3 -> 1.0\n",
      "seq3 -> 3.0\n",
      "Deptext -> Over the past two weeks, I have not been depressed.  I have been interested in things as much as I normally have been.  I have been in a good mood and I have been motivated to do things.  I have been engaged in my normal activities and my sleep has been pretty good.\n",
      "Wortext -> Over the last two weeks, I have not been worried.  I am not worried about coronavirus, because I am working from home and take all the necessary precautions.  Things have been going my way recently and I have been making a lot of things happening.\n",
      "DepselectCol[happy] -> nan\n",
      "DepselectCol[sad] -> nan\n",
      "DepselectCol[content] -> nan\n",
      "DepselectCol[joyful] -> Y\n",
      "DepselectCol[satisfied] -> nan\n",
      "DepselectCol[tired] -> nan\n",
      "DepselectCol[peaceful] -> nan\n",
      "DepselectCol[cheerful] -> Y\n",
      "DepselectCol[excited] -> nan\n",
      "DepselectCol[calm] -> nan\n",
      "DepselectCol[hopeful] -> Y\n",
      "DepselectCol[down] -> nan\n",
      "DepselectCol[anxious] -> nan\n",
      "DepselectCol[unhappy] -> nan\n",
      "DepselectCol[worried] -> nan\n",
      "DepselectCol[optimistic] -> nan\n",
      "DepselectCol[blue] -> nan\n",
      "DepselectCol[lonely] -> nan\n",
      "DepselectCol[relaxed] -> Y\n",
      "DepselectCol[pleased] -> nan\n",
      "DepselectCol[stressed] -> nan\n",
      "DepselectCol[depressed] -> nan\n",
      "DepselectCol[active] -> Y\n",
      "DepselectCol[angry] -> nan\n",
      "DepselectCol[fun] -> nan\n",
      "DepselectCol[loving] -> nan\n",
      "DepselectCol[upbeat] -> nan\n",
      "DepselectCol[blessed] -> nan\n",
      "DepselectCol[joy] -> nan\n",
      "DepselectCol[love] -> nan\n",
      "DepselectCol[loved] -> nan\n",
      "WorselectCol[anxious] -> nan\n",
      "WorselectCol[calm] -> nan\n",
      "WorselectCol[happy] -> Y\n",
      "WorselectCol[nervous] -> nan\n",
      "WorselectCol[relaxed] -> nan\n",
      "WorselectCol[concerned] -> nan\n",
      "WorselectCol[worried] -> nan\n",
      "WorselectCol[content] -> nan\n",
      "WorselectCol[stressed] -> nan\n",
      "WorselectCol[peaceful] -> nan\n",
      "WorselectCol[upset] -> nan\n",
      "WorselectCol[tense] -> nan\n",
      "WorselectCol[scared] -> nan\n",
      "WorselectCol[carefree] -> Y\n",
      "WorselectCol[uneasy] -> nan\n",
      "WorselectCol[fearful] -> nan\n",
      "WorselectCol[hopeful] -> nan\n",
      "WorselectCol[sad] -> nan\n",
      "WorselectCol[satisfied] -> Y\n",
      "WorselectCol[stress] -> nan\n",
      "WorselectCol[money] -> nan\n",
      "WorselectCol[anxiety] -> nan\n",
      "WorselectCol[fear] -> nan\n",
      "WorselectCol[tired] -> nan\n",
      "WorselectCol[unworried] -> nan\n",
      "WorselectCol[troubled] -> nan\n",
      "WorselectCol[confident] -> Y\n",
      "WorselectCol[thoughtful] -> nan\n",
      "WorselectCol[bothered] -> nan\n",
      "WorselectCol[peace] -> Y\n",
      "WorselectCol[untroubled] -> nan\n",
      "PHQ[SQ01] -> 0.0\n",
      "PHQ[SQ02] -> 0.0\n",
      "PHQ[SQ03] -> 0.0\n",
      "PHQ[SQ04] -> 0.0\n",
      "PHQ[SQ05] -> 0.0\n",
      "PHQ[SQ06] -> 0.0\n",
      "PHQ[SQ07] -> 0.0\n",
      "PHQ[SQ08] -> 0.0\n",
      "PHQ[SQ09] -> 0.0\n",
      "PHQ[SQ10] -> 2.0\n",
      "PHQextra -> nan\n",
      "CESD[SQ01] -> 0.0\n",
      "CESD[SQ02] -> 0.0\n",
      "CESD[SQ03] -> 0.0\n",
      "CESD[SQ04] -> 3.0\n",
      "CESD[SQ05] -> 0.0\n",
      "CESD[SQ06] -> 0.0\n",
      "CESD[SQ07] -> 0.0\n",
      "CESD[SQ08] -> 3.0\n",
      "CESD[SQ09] -> 0.0\n",
      "CESD[SQ10] -> 0.0\n",
      "CESD[SQ11] -> 0.0\n",
      "CESD[SQ12] -> 3.0\n",
      "CESD[SQ13] -> 0.0\n",
      "CESD[SQ14] -> 0.0\n",
      "CESD[SQ15] -> 0.0\n",
      "CESD[SQ16] -> 2.0\n",
      "CESD[SQ17] -> 0.0\n",
      "CESD[SQ18] -> 0.0\n",
      "CESD[SQ19] -> 0.0\n",
      "CESD[SQ20] -> 0.0\n",
      "GADsurvey[SQ01] -> 0.0\n",
      "GADsurvey[SQ02] -> 0.0\n",
      "GADsurvey[SQ03] -> 0.0\n",
      "GADsurvey[SQ04] -> 0.0\n",
      "GADsurvey[SQ05] -> 0.0\n",
      "GADsurvey[SQ06] -> 1.0\n",
      "GADsurvey[SQ07] -> 0.0\n",
      "GADsurvey[SQ08] -> 1.0\n",
      "GADextra -> 0.0\n",
      "PSWQsurvey[SQ01] -> 3.0\n",
      "PSWQsurvey[SQ02] -> 1.0\n",
      "PSWQsurvey[SQ03] -> 3.0\n",
      "PSWQsurvey[SQ04] -> 1.0\n",
      "PSWQsurvey[SQ05] -> 1.0\n",
      "PSWQsurvey[SQ06] -> 2.0\n",
      "PSWQsurvey[SQ07] -> 1.0\n",
      "PSWQsurvey[SQ08] -> 3.0\n",
      "PSWQsurvey[SQ09] -> 1.0\n",
      "PSWQsurvey[SQ10] -> 3.0\n",
      "PSWQsurvey[SQ11] -> 3.0\n",
      "PSWQsurvey[SQ12] -> 1.0\n",
      "PSWQsurvey[SQ13] -> 2.0\n",
      "PSWQsurvey[SQ14] -> 1.0\n",
      "PSWQsurvey[SQ15] -> 1.0\n",
      "PSWQsurvey[SQ16] -> 1.0\n",
      "A1 -> 0.0\n",
      "A2 -> 0.0\n",
      "A3a -> 0\n",
      "A3b1 -> 0\n",
      "A3c1 -> 0\n",
      "A3d1 -> 0\n",
      "A3e1 -> 0\n",
      "A3f1 -> 0\n",
      "A3g1 -> 0\n",
      "A4a -> nan\n",
      "A5 -> nan\n",
      "A6 -> nan\n",
      "N1a -> 0\n",
      "N1a2 -> 0\n",
      "N1b -> 0\n",
      "N2 -> 0\n",
      "N3a -> 0\n",
      "N3b -> 0\n",
      "N3c -> 0\n",
      "N3d -> 0\n",
      "N3e -> 0\n",
      "N3f -> 0\n",
      "N4 -> 0\n",
      "Diagnosis[SQ01] -> nan\n",
      "Diagnosis[SQ02] -> nan\n",
      "Diagnosis[SQ03] -> nan\n",
      "Diagnosis[SQ04] -> Y\n",
      "SickDaysMonth -> 0.0\n",
      "MentalSickDays -> 0.0\n",
      "SickDaysYear -> 0.0\n",
      "MentalSickDaysYear -> 0.0\n",
      "HealthCareVisits -> 0.0\n",
      "HealthCareMental -> 0.0\n",
      "Treatment[SQ01] -> Y\n",
      "Treatment[SQ02] -> nan\n",
      "Treatment[SQ03] -> nan\n",
      "Treatment[SQ04] -> nan\n",
      "Treatment[other] -> nan\n",
      "Gender -> 1.0\n",
      "Age -> 30.0\n",
      "interviewtime -> nan\n",
      "ProlificIDTime -> nan\n",
      "sequence1Time -> nan\n",
      "seqOneTime -> nan\n",
      "Dep5wordsTime -> nan\n",
      "Wor5wordsTime -> nan\n",
      "sequence2Time -> nan\n",
      "seq2Time -> nan\n",
      "Dep5phraseorwordsTime -> nan\n",
      "Wor5phraseorwordsTime -> nan\n",
      "sequence3Time -> nan\n",
      "seq3Time -> nan\n",
      "DeptextTime -> nan\n",
      "WortextTime -> nan\n",
      "DepselectColTime -> nan\n",
      "WorselectColTime -> nan\n",
      "PHQTime -> nan\n",
      "PHQextraTime -> nan\n",
      "CESDTime -> nan\n",
      "GADsurveyTime -> nan\n",
      "GADextraTime -> nan\n",
      "PSWQsurveyTime -> nan\n",
      "A1Time -> nan\n",
      "A2Time -> nan\n",
      "A3aTime -> nan\n",
      "A3b1Time -> nan\n",
      "A3c1Time -> nan\n",
      "A3d1Time -> nan\n",
      "A3e1Time -> nan\n",
      "A3f1Time -> nan\n",
      "A3g1Time -> nan\n",
      "A4aTime -> nan\n",
      "A5Time -> nan\n",
      "A6Time -> nan\n",
      "N1aTime -> nan\n",
      "N1a2Time -> nan\n",
      "N1bTime -> nan\n",
      "N2Time -> nan\n",
      "N3aTime -> nan\n",
      "N3bTime -> nan\n",
      "N3cTime -> nan\n",
      "N3dTime -> nan\n",
      "N3eTime -> nan\n",
      "N3fTime -> nan\n",
      "N4Time -> nan\n",
      "DiagnosisTime -> nan\n",
      "SickDaysMonthTime -> nan\n",
      "MentalSickDaysTime -> nan\n",
      "SickDaysYearTime -> nan\n",
      "MentalSickDaysYearTime -> nan\n",
      "HealthCareVisitsTime -> nan\n",
      "HealthCareMentalTime -> nan\n",
      "TreatmentTime -> nan\n",
      "GenderTime -> nan\n",
      "AgeTime -> nan\n",
      "session_id -> 5f2d3ce80659d02a3948e4dc\n",
      "status -> APPROVED\n",
      "started_datetime -> 2020-08-07 11:37:52\n",
      "completed_date_time -> 2020-08-07 11:46:41\n",
      "time_taken -> 529.155\n",
      "age -> 33.0\n",
      "num_approvals -> 1651.0\n",
      "num_rejections -> 1.0\n",
      "prolific_score -> 100.0\n",
      "reviewed_at_datetime -> 2020-08-07 17:36:19\n",
      "entered_code -> 4536C388\n",
      "Country of Birth -> United States\n",
      "Current Country of Residence -> United States\n",
      "Employment Status -> DATA EXPIRED\n",
      "First Language -> English\n",
      "Nationality -> United States\n",
      "Sex -> Male\n",
      "Student Status -> DATA EXPIRED\n",
      "PHQ1 -> 0.0\n",
      "PHQ2 -> 0.0\n",
      "PHQ3 -> 0.0\n",
      "PHQ4 -> 0.0\n",
      "PHQ5 -> 0.0\n",
      "PHQ6 -> 0.0\n",
      "PHQ7 -> 0.0\n",
      "PHQ8 -> 0.0\n",
      "PHQ9 -> 0.0\n",
      "PHQ_control2 -> 2.0\n",
      "CESD1 -> 0.0\n",
      "CESD2 -> 0.0\n",
      "CESD3 -> 0.0\n",
      "CESD4 -> 3.0\n",
      "CESD5 -> 0.0\n",
      "CESD6 -> 0.0\n",
      "CESD7 -> 0.0\n",
      "CESD8 -> 3.0\n",
      "CESD9 -> 0.0\n",
      "CESD10 -> 0.0\n",
      "CESD11 -> 0.0\n",
      "CESD12 -> 3.0\n",
      "CESD13 -> 0.0\n",
      "CESD14 -> 0.0\n",
      "CESD15 -> 0.0\n",
      "CESD16 -> 2.0\n",
      "CESD17 -> 0.0\n",
      "CESD18 -> 0.0\n",
      "CESD19 -> 0.0\n",
      "CESD20 -> 0.0\n",
      "GAD1 -> 0.0\n",
      "GAD2 -> 0.0\n",
      "GAD3 -> 0.0\n",
      "GAD4 -> 0.0\n",
      "GAD5 -> 0.0\n",
      "GAD6 -> 1.0\n",
      "GAD7 -> 0.0\n",
      "GADcontrol1 -> 1.0\n",
      "PSWQ1 -> 3.0\n",
      "PSWQ2 -> 1.0\n",
      "PSWQ3 -> 3.0\n",
      "PSWQ4 -> 1.0\n",
      "PSWQ5 -> 1.0\n",
      "PSWQ6 -> 2.0\n",
      "PSWQ7 -> 1.0\n",
      "PSWQ8 -> 3.0\n",
      "PSWQ9 -> 1.0\n",
      "PSWQ10 -> 3.0\n",
      "PSWQ11 -> 3.0\n",
      "PSWQ12 -> 1.0\n",
      "PSWQ13 -> 2.0\n",
      "PSWQ14 -> 1.0\n",
      "PSWQ15 -> 1.0\n",
      "PSWQ16 -> 1.0\n",
      "PHQtot -> 0.0\n",
      "GADtot -> 1.0\n",
      "PSWQtot -> 10.0\n",
      "CESD4rev -> 0.0\n",
      "CESD8rev -> 0.0\n",
      "CESD12rev -> 0.0\n",
      "CESD16rev -> 1.0\n",
      "CESDtot -> 1.0\n",
      "dep_all_words -> motivated learning passionate enthusiastic happy\n",
      "wor_all_words -> motivated enthusiastic learning exercise nutrition\n",
      "dep_all_phraces -> happy eager to learn restful sleep motivated joyful\n",
      "wor_all_phraces -> content improving learning motivated better than before\n",
      "dep_text -> Over the past two weeks, I have not been depressed.  I have been interested in things as much as I normally have been.  I have been in a good mood and I have been motivated to do things.  I have been engaged in my normal activities and my sleep has been pretty good.\n",
      "wor_text -> Over the last two weeks, I have not been worried.  I am not worried about coronavirus, because I am working from home and take all the necessary precautions.  Things have been going my way recently and I have been making a lot of things happening.\n",
      "DepselectCol_happy -> nan\n",
      "DepselectCol_sad -> nan\n",
      "DepselectCol_content -> nan\n",
      "DepselectCol_joyful -> joyful\n",
      "DepselectCol_satisfied -> nan\n",
      "DepselectCol_tired -> nan\n",
      "DepselectCol_peaceful -> nan\n",
      "DepselectCol_cheerful -> cheerful\n",
      "DepselectCol_excited -> nan\n",
      "DepselectCol_calm -> nan\n",
      "DepselectCol_hopeful -> hopeful\n",
      "DepselectCol_down -> nan\n",
      "DepselectCol_anxious -> nan\n",
      "DepselectCol_unhappy -> nan\n",
      "DepselectCol_worried -> nan\n",
      "DepselectCol_optimistic -> nan\n",
      "DepselectCol_blue -> nan\n",
      "DepselectCol_lonely -> nan\n",
      "DepselectCol_relaxed -> relaxed\n",
      "DepselectCol_pleased -> nan\n",
      "DepselectCol_stressed -> nan\n",
      "DepselectCol_depressed -> nan\n",
      "DepselectCol_active -> active\n",
      "DepselectCol_angry -> nan\n",
      "DepselectCol_fun -> nan\n",
      "DepselectCol_loving -> nan\n",
      "DepselectCol_upbeat -> nan\n",
      "DepselectCol_blessed -> nan\n",
      "DepselectCol_joy -> nan\n",
      "DepselectCol_love -> nan\n",
      "dep_all_selected -> NA NA NA joyful NA NA NA cheerful NA NA hopeful NA NA NA NA NA NA NA relaxed NA NA NA active NA NA NA NA NA NA NA\n",
      "dep_all_selected1 ->    joyful    cheerful   hopeful        relaxed    active       \n",
      "WorselectCol_anxious -> nan\n",
      "WorselectCol_calm -> nan\n",
      "WorselectCol_happy -> happy\n",
      "WorselectCol_nervous -> nan\n",
      "WorselectCol_relaxed -> nan\n",
      "WorselectCol_concerned -> nan\n",
      "WorselectCol_worried -> nan\n",
      "WorselectCol_content -> nan\n",
      "WorselectCol_stressed -> nan\n",
      "WorselectCol_peaceful -> nan\n",
      "WorselectCol_upset -> nan\n",
      "WorselectCol_tense -> nan\n",
      "WorselectCol_scared -> nan\n",
      "WorselectCol_carefree -> carefree\n",
      "WorselectCol_uneasy -> nan\n",
      "WorselectCol_fearful -> nan\n",
      "WorselectCol_hopeful -> nan\n",
      "WorselectCol_sad -> nan\n",
      "WorselectCol_satisfied -> satisfied\n",
      "WorselectCol_stress -> nan\n",
      "WorselectCol_money -> nan\n",
      "WorselectCol_anxiety -> nan\n",
      "WorselectCol_fear -> nan\n",
      "WorselectCol_tired -> nan\n",
      "WorselectCol_unworried -> nan\n",
      "WorselectCol_troubled -> nan\n",
      "WorselectCol_confident -> confident\n",
      "WorselectCol_thoughtful -> nan\n",
      "WorselectCol_bothered -> nan\n",
      "WorselectCol_peace -> peace\n",
      "WorselectCol_untroubled -> nan\n",
      "wor_all_selected -> NA NA happy NA NA NA NA NA NA NA NA NA NA carefree NA NA NA NA satisfied NA NA NA NA NA NA NA confident NA NA peace NA\n",
      "wor_all_selected1 ->   happy           carefree     satisfied        confident   peace \n",
      "minidep_scale -> 0.0\n",
      "minidep_diagnose -> 0\n",
      "depression_episodes -> 0\n",
      "miniGAD_scale -> 0\n",
      "miniGAD_symptoms_scale -> 0\n",
      "miniGAD_diagnose -> 0\n",
      "minidiagnose_category -> NoDi\n",
      "minidiagnose_category_number -> 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Only for understanding data and visualize a response example.\n",
    "Prints column name and response of patient at row 0.\n",
    "\"\"\"\n",
    "for res, col in zip(responses.iloc[0], responses.columns):\n",
    "    print(\"{} -> {}\".format(col, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using 5-gram contexts from the database, a co-occurrence (word by word) matrix was set up, \n",
    "where the rows contained the 120,000 most common words in the n-gram database and the columns \n",
    "consisted of the 10,000 most common words in the n-gram database.\n",
    "\n",
    "The variable 'space' is a matrix of the semantic space with dimentions reduced to 512.\n",
    "\"\"\"\n",
    "space = pd.read_csv('data/spaceEnglish1.csv', encoding= 'unicode_escape')\n",
    "space.set_index('words', inplace=True)\n",
    "space.drop(space.columns[[0]], axis=1, inplace=True)\n",
    "space.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X503</th>\n",
       "      <th>X504</th>\n",
       "      <th>X505</th>\n",
       "      <th>X506</th>\n",
       "      <th>X507</th>\n",
       "      <th>X508</th>\n",
       "      <th>X509</th>\n",
       "      <th>X510</th>\n",
       "      <th>X511</th>\n",
       "      <th>X512</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>-0.234071</td>\n",
       "      <td>-0.278211</td>\n",
       "      <td>-0.100658</td>\n",
       "      <td>-0.269570</td>\n",
       "      <td>-0.115498</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.036835</td>\n",
       "      <td>0.024037</td>\n",
       "      <td>-0.003974</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011414</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>-0.020312</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>0.012867</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>-0.020382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>-0.283230</td>\n",
       "      <td>-0.338776</td>\n",
       "      <td>-0.141085</td>\n",
       "      <td>-0.243715</td>\n",
       "      <td>-0.236692</td>\n",
       "      <td>-0.033354</td>\n",
       "      <td>-0.099906</td>\n",
       "      <td>0.053253</td>\n",
       "      <td>-0.025582</td>\n",
       "      <td>-0.040372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028472</td>\n",
       "      <td>0.048824</td>\n",
       "      <td>-0.025452</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.027658</td>\n",
       "      <td>-0.022135</td>\n",
       "      <td>0.023037</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>-0.001482</td>\n",
       "      <td>-0.024063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>-0.251058</td>\n",
       "      <td>-0.327183</td>\n",
       "      <td>-0.203889</td>\n",
       "      <td>-0.283337</td>\n",
       "      <td>-0.124522</td>\n",
       "      <td>-0.006537</td>\n",
       "      <td>0.015371</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>-0.130597</td>\n",
       "      <td>0.055605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>-0.012646</td>\n",
       "      <td>-0.005019</td>\n",
       "      <td>0.075544</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>-0.022636</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>-0.027951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>-0.281888</td>\n",
       "      <td>-0.346746</td>\n",
       "      <td>-0.171006</td>\n",
       "      <td>-0.266698</td>\n",
       "      <td>-0.208917</td>\n",
       "      <td>-0.019832</td>\n",
       "      <td>-0.035404</td>\n",
       "      <td>0.044301</td>\n",
       "      <td>-0.076601</td>\n",
       "      <td>0.021328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019319</td>\n",
       "      <td>0.042742</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.034352</td>\n",
       "      <td>0.033282</td>\n",
       "      <td>-0.006843</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>-0.013623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.256530</td>\n",
       "      <td>-0.335434</td>\n",
       "      <td>-0.229791</td>\n",
       "      <td>-0.256070</td>\n",
       "      <td>-0.120020</td>\n",
       "      <td>0.017080</td>\n",
       "      <td>0.078004</td>\n",
       "      <td>0.112134</td>\n",
       "      <td>-0.073805</td>\n",
       "      <td>0.098183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>-0.022383</td>\n",
       "      <td>-0.042172</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.013435</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>-0.022769</td>\n",
       "      <td>0.024873</td>\n",
       "      <td>0.010061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X1        X2        X3        X4        X5        X6        X7  \\\n",
       "words                                                                         \n",
       "was   -0.234071 -0.278211 -0.100658 -0.269570 -0.115498 -0.000038 -0.036835   \n",
       "not   -0.283230 -0.338776 -0.141085 -0.243715 -0.236692 -0.033354 -0.099906   \n",
       "by    -0.251058 -0.327183 -0.203889 -0.283337 -0.124522 -0.006537  0.015371   \n",
       "that  -0.281888 -0.346746 -0.171006 -0.266698 -0.208917 -0.019832 -0.035404   \n",
       "of    -0.256530 -0.335434 -0.229791 -0.256070 -0.120020  0.017080  0.078004   \n",
       "\n",
       "             X8        X9       X10  ...      X503      X504      X505  \\\n",
       "words                                ...                                 \n",
       "was    0.024037 -0.003974  0.006582  ... -0.011414  0.018075 -0.020312   \n",
       "not    0.053253 -0.025582 -0.040372  ... -0.028472  0.048824 -0.025452   \n",
       "by     0.131667 -0.130597  0.055605  ... -0.001550  0.027915 -0.012646   \n",
       "that   0.044301 -0.076601  0.021328  ...  0.019319  0.042742  0.001747   \n",
       "of     0.112134 -0.073805  0.098183  ...  0.012012  0.005470 -0.022383   \n",
       "\n",
       "           X506      X507      X508      X509      X510      X511      X512  \n",
       "words                                                                        \n",
       "was    0.001287  0.024483  0.012867  0.021265  0.016368  0.024858 -0.020382  \n",
       "not    0.007828  0.027658 -0.022135  0.023037  0.005371 -0.001482 -0.024063  \n",
       "by    -0.005019  0.075544  0.014663  0.013489 -0.022636  0.010127 -0.027951  \n",
       "that   0.019198  0.022598  0.034352  0.033282 -0.006843  0.027052 -0.013623  \n",
       "of    -0.042172 -0.003430 -0.013435  0.003697 -0.022769  0.024873  0.010061  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Controlling for artifacts relating to frequently occurring words.\n",
    "\n",
    "1) Calculate, from Google N-gram, a frequency weighted average of all semantic representations in the space.\n",
    "   (So that the weighting is proportional to how frequently the words occur in Google N-gram.)\n",
    "2) Subtract this mean prior to aggregating each word, and then add to the final value.\n",
    "\"\"\"\n",
    "\n",
    "def aggregating_words(responses):\n",
    "    res_arr = np.zeros(512)\n",
    "    #mean_array=np.array(responses).astype(np.float)\n",
    "    #space_mean = np.mean(mean_array, axis=0)\n",
    "    \n",
    "    for word in responses:\n",
    "        word_arr = np.array(space.loc[word])\n",
    "        res_arr = res_arr + word_arr# - space_mean\n",
    "    \n",
    "    #res_arr += space_mean    \n",
    "    res_arr = res_arr / res_arr.sum() # Normalizing aggregated vector\n",
    "    return res_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleans the string from punctuations and removes all words which are not represented in the semantic space. \n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "\n",
    "words_in_space = set(space.index.values)\n",
    "\n",
    "def clean_text(text):\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        text = list(set(text.split()))\n",
    "        cleaned_words = [w for w in text if w in words_in_space]\n",
    "        return cleaned_words\n",
    "    except Exception as e: \n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For one row extracts the string of words/text from the important columns. \n",
    "The strings are cleaned using the clean_text function and a list of all words (without duplicates) is returned.\n",
    "\"\"\"\n",
    "\n",
    "def extract_words_dep(inx):\n",
    "    important_columns = ['Deptext','dep_all_phraces', 'dep_all_words',  'dep_all_selected1']\n",
    "    all_responded_words_dep = []\n",
    "    res = responses.iloc[inx]\n",
    "    for column_name in important_columns:\n",
    "        words_in_column = res[column_name]\n",
    "        if isinstance(words_in_column, str): \n",
    "            words = clean_text(words_in_column)\n",
    "            for word in words:\n",
    "                if word not in all_responded_words_dep:\n",
    "                    all_responded_words_dep.append(word)\n",
    "    return all_responded_words_dep\n",
    "\n",
    "def extract_words_anx(inx):\n",
    "    important_columns = ['Wortext', 'wor_all_phraces', 'wor_all_words',  'wor_all_selected1']\n",
    "    all_responded_words_anx = []\n",
    "    res = responses.iloc[inx]\n",
    "    \n",
    "    for column_name in important_columns:\n",
    "        words_in_column = res[column_name]\n",
    "        if isinstance(words_in_column, str): \n",
    "            words = clean_text(words_in_column)\n",
    "            for word in words:\n",
    "                if word not in all_responded_words_anx:\n",
    "                    all_responded_words_anx.append(word)\n",
    "    return all_responded_words_anx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Goes through all rows in response dataframe and for each person, converts all the words to an aggregated vector\n",
    "and adds this to a dictionary to later be converted to a dataframe. \n",
    "\"\"\"\n",
    "\n",
    "all_responses_space_dep = {}\n",
    "all_responses_space_anx = {}\n",
    "\n",
    "for i in range(len(responses.index)):\n",
    "    words_dep = extract_words_dep(i)\n",
    "    words_anx = extract_words_anx(i)\n",
    "    try:\n",
    "        all_responses_space_dep[i] = aggregating_words(words_dep)\n",
    "        all_responses_space_anx[i] = aggregating_words(words_anx)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates a dataframe with dimension (nbr of participants x 512).\n",
    "Each row stores the aggregated semantic vector representations of one persons responses.\n",
    "\n",
    "This matrix can then be used for the analysis steps. \n",
    "\"\"\"\n",
    "vectors_dep = list(all_responses_space_dep.values())\n",
    "vectors_anx=list(all_responses_space_anx.values())\n",
    "cols = list(space.columns)\n",
    "response_space_dep = pd.DataFrame(vectors_dep, columns = cols) \n",
    "response_space_anx=pd.DataFrame(vectors_anx, columns = cols) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important variables \n",
    "\n",
    "Deptext = Depression text-response <br> \n",
    "Wortext = Worry text-response\n",
    "\n",
    "dep_all_phraces = Depression all phraces responses <br> \n",
    "wor_all_phraces = Worry all phraces responses\n",
    "\n",
    "dep_all_word = Depression all descriptive word responses <br>\n",
    "wor_all_words = Worry all descriptive word responses\n",
    "\n",
    "dep_all_selected1 = All selected depression word responses <br>\n",
    "wor_all_selected1 = All selected worry word responses\n",
    "\n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "CESDtot = Center for Epidemiological Studies Depression (CESD) <br>\n",
    "PHQtot = PHQ-9 = Patient Helath Questionnaire = a depression scale\n",
    "\n",
    "GADtot = GAD-7 = Generalized anxiety disorder scale <br>\n",
    "PSWQtot = Penn State Worry Questionniare \n",
    "\n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "miniGAD_diagnose = Self-reported MINI (structured interview) GAD diangose <br>\n",
    "minidep_diagnose = Self-reported MINI (structured interview) MDD (depression) diangose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Semantic Representations in Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resp_dep_scale=responses[['minidep_scale']]\n",
    "resp_GAD_scale=responses[['miniGAD_scale']]\n",
    "#Checking for NaN values\n",
    "resp_dep_scale.isnull().values.any() #true\n",
    "resp_GAD_scale.isnull().values.any() #false\n",
    "\n",
    "y_anxiety= resp_GAD_scale.values\n",
    "y_dep=resp_dep_scale.values \n",
    "\n",
    "#Replaceing NaN values with mean value of column - perhaps we should do this differently\n",
    "col_mean = np.nanmean(y_dep, axis=0)\n",
    "col_mean=np.around(col_mean, decimals=0, out=None) #rounding \n",
    "#Find indices that you need to replace\n",
    "inds = np.where(np.isnan(y_dep))\n",
    "#Place column means in the indices. Align the array using take\n",
    "y_dep[inds] = np.take(col_mean, inds[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Semantic-numeric correlations. \n",
    "Analyzing the relationship between semantic responses and a numerical variable\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Predicting the corresponding numeric rating scales on the basis of these representations by means \n",
    "of multiple linear regression analyses \"\"\"\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regr = LinearRegression()\n",
    "\n",
    "#x_dep = response_space_dep\n",
    "#x_anx = response_space_anx\n",
    "#splitting data into training and testing dataset\n",
    "\n",
    "#X_train_dep, X_test_dep, y_train_dep, y_test_dep = train_test_split(x_dep, y_dep, test_size=0.2,random_state=0)\n",
    "#regr.fit(X_train_dep, y_train_dep) \n",
    "\n",
    "# Predicting the test set results\n",
    "#y_pred_dep = regr.predict(X_test_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"When the predicted variable is categorical, multinomial logistic regression is used.\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
