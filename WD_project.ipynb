{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitdate</th>\n",
       "      <th>lastpage</th>\n",
       "      <th>startlanguage</th>\n",
       "      <th>seed</th>\n",
       "      <th>startdate</th>\n",
       "      <th>datestamp</th>\n",
       "      <th>sequence1</th>\n",
       "      <th>seqOne</th>\n",
       "      <th>Dep5words[Word1]</th>\n",
       "      <th>...</th>\n",
       "      <th>wor_all_selected</th>\n",
       "      <th>wor_all_selected1</th>\n",
       "      <th>minidep_scale</th>\n",
       "      <th>minidep_diagnose</th>\n",
       "      <th>depression_episodes</th>\n",
       "      <th>miniGAD_scale</th>\n",
       "      <th>miniGAD_symptoms_scale</th>\n",
       "      <th>miniGAD_diagnose</th>\n",
       "      <th>minidiagnose_category</th>\n",
       "      <th>minidiagnose_category_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434.0</td>\n",
       "      <td>2020-08-07 11:46:22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>6.593644e+08</td>\n",
       "      <td>2020-08-07 11:38:22</td>\n",
       "      <td>2020-08-07 11:46:22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motivated</td>\n",
       "      <td>...</td>\n",
       "      <td>NA NA happy NA NA NA NA NA NA NA NA NA NA care...</td>\n",
       "      <td>happy           carefree     satisfied      ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184.0</td>\n",
       "      <td>2020-08-07 11:58:36</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>2.803892e+08</td>\n",
       "      <td>2020-08-07 11:34:31</td>\n",
       "      <td>2020-08-07 11:58:36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>connected</td>\n",
       "      <td>...</td>\n",
       "      <td>anxious NA NA NA NA NA NA NA NA NA NA tense NA...</td>\n",
       "      <td>anxious           tense    fearful  sad     fe...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330.0</td>\n",
       "      <td>2020-08-07 11:51:54</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>6.770686e+07</td>\n",
       "      <td>2020-08-07 11:36:32</td>\n",
       "      <td>2020-08-07 11:51:54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>anxious NA NA NA NA NA worried NA NA NA NA NA ...</td>\n",
       "      <td>anxious      worried      scared     sad   mon...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630.0</td>\n",
       "      <td>2020-08-07 13:22:42</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.176643e+09</td>\n",
       "      <td>2020-08-07 12:55:26</td>\n",
       "      <td>2020-08-07 13:22:42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>minor</td>\n",
       "      <td>...</td>\n",
       "      <td>anxious NA NA NA NA concerned NA NA NA NA NA t...</td>\n",
       "      <td>anxious     concerned      tense scared       ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400.0</td>\n",
       "      <td>2020-08-07 12:04:52</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.012492e+09</td>\n",
       "      <td>2020-08-07 11:37:19</td>\n",
       "      <td>2020-08-07 12:04:52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>family</td>\n",
       "      <td>...</td>\n",
       "      <td>NA NA NA NA NA concerned NA NA NA NA NA tense ...</td>\n",
       "      <td>concerned      tense      sad      tired ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>GAD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id           submitdate  lastpage startlanguage          seed  \\\n",
       "0  434.0  2020-08-07 11:46:22      15.0            en  6.593644e+08   \n",
       "1  184.0  2020-08-07 11:58:36      15.0            en  2.803892e+08   \n",
       "2  330.0  2020-08-07 11:51:54      15.0            en  6.770686e+07   \n",
       "3  630.0  2020-08-07 13:22:42      15.0            en  1.176643e+09   \n",
       "4  400.0  2020-08-07 12:04:52      15.0            en  1.012492e+09   \n",
       "\n",
       "             startdate            datestamp  sequence1  seqOne  \\\n",
       "0  2020-08-07 11:38:22  2020-08-07 11:46:22        2.0     1.0   \n",
       "1  2020-08-07 11:34:31  2020-08-07 11:58:36        2.0     1.0   \n",
       "2  2020-08-07 11:36:32  2020-08-07 11:51:54        1.0     1.0   \n",
       "3  2020-08-07 12:55:26  2020-08-07 13:22:42        3.0     1.0   \n",
       "4  2020-08-07 11:37:19  2020-08-07 12:04:52        1.0     1.0   \n",
       "\n",
       "  Dep5words[Word1]  ...                                   wor_all_selected  \\\n",
       "0        motivated  ...  NA NA happy NA NA NA NA NA NA NA NA NA NA care...   \n",
       "1        connected  ...  anxious NA NA NA NA NA NA NA NA NA NA tense NA...   \n",
       "2              Yes  ...  anxious NA NA NA NA NA worried NA NA NA NA NA ...   \n",
       "3            minor  ...  anxious NA NA NA NA concerned NA NA NA NA NA t...   \n",
       "4           family  ...  NA NA NA NA NA concerned NA NA NA NA NA tense ...   \n",
       "\n",
       "                                   wor_all_selected1 minidep_scale  \\\n",
       "0    happy           carefree     satisfied      ...           0.0   \n",
       "1  anxious           tense    fearful  sad     fe...           3.0   \n",
       "2  anxious      worried      scared     sad   mon...           7.0   \n",
       "3  anxious     concerned      tense scared       ...           3.0   \n",
       "4       concerned      tense      sad      tired ...           4.0   \n",
       "\n",
       "  minidep_diagnose depression_episodes miniGAD_scale miniGAD_symptoms_scale  \\\n",
       "0                0                   0             0                      0   \n",
       "1                0                   0             8                      5   \n",
       "2                0                   5             9                      5   \n",
       "3                0                   5             8                      5   \n",
       "4                0                   2             7                      4   \n",
       "\n",
       "  miniGAD_diagnose minidiagnose_category  minidiagnose_category_number  \n",
       "0                0                  NoDi                             0  \n",
       "1                0                  NoDi                             0  \n",
       "2                0                  NoDi                             0  \n",
       "3                0                  NoDi                             0  \n",
       "4                1                   GAD                             2  \n",
       "\n",
       "[5 rows x 407 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "#Get relative directory to find path\n",
    "path = os.path.join(os.getcwd(), 'data', 'response_format_cleaned_ds1.csv')\n",
    "responses = pd.read_csv(path, sep=';', header=0)\n",
    "responses.drop(responses.columns[[0]], axis=1, inplace=True)\n",
    "responses.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id -> 434.0\n",
      "submitdate -> 2020-08-07 11:46:22\n",
      "lastpage -> 15.0\n",
      "startlanguage -> en\n",
      "seed -> 659364415.0\n",
      "startdate -> 2020-08-07 11:38:22\n",
      "datestamp -> 2020-08-07 11:46:22\n",
      "sequence1 -> 2.0\n",
      "seqOne -> 1.0\n",
      "Dep5words[Word1] -> motivated\n",
      "Dep5words[Word2] -> learning\n",
      "Dep5words[Word3] -> passionate\n",
      "Dep5words[Word4] -> enthusiastic\n",
      "Dep5words[Word5] -> happy\n",
      "Wor5words[SQ01] -> motivated\n",
      "Wor5words[SQ02] -> enthusiastic\n",
      "Wor5words[SQ03] -> learning\n",
      "Wor5words[SQ04] -> exercise\n",
      "Wor5words[SQ05] -> nutrition\n",
      "sequence2 -> 3.0\n",
      "seq2 -> 2.0\n",
      "Dep5phraseorwords[SQ01] -> happy\n",
      "Dep5phraseorwords[SQ02] -> eager to learn\n",
      "Dep5phraseorwords[SQ03] -> restful sleep\n",
      "Dep5phraseorwords[SQ04] -> motivated\n",
      "Dep5phraseorwords[SQ05] -> joyful\n",
      "Wor5phraseorwords[SQ01] -> content\n",
      "Wor5phraseorwords[SQ02] -> improving\n",
      "Wor5phraseorwords[SQ03] -> learning\n",
      "Wor5phraseorwords[SQ04] -> motivated\n",
      "Wor5phraseorwords[SQ05] -> better than before\n",
      "sequence3 -> 1.0\n",
      "seq3 -> 3.0\n",
      "Deptext -> Over the past two weeks, I have not been depressed.  I have been interested in things as much as I normally have been.  I have been in a good mood and I have been motivated to do things.  I have been engaged in my normal activities and my sleep has been pretty good.\n",
      "Wortext -> Over the last two weeks, I have not been worried.  I am not worried about coronavirus, because I am working from home and take all the necessary precautions.  Things have been going my way recently and I have been making a lot of things happening.\n",
      "DepselectCol[happy] -> nan\n",
      "DepselectCol[sad] -> nan\n",
      "DepselectCol[content] -> nan\n",
      "DepselectCol[joyful] -> Y\n",
      "DepselectCol[satisfied] -> nan\n",
      "DepselectCol[tired] -> nan\n",
      "DepselectCol[peaceful] -> nan\n",
      "DepselectCol[cheerful] -> Y\n",
      "DepselectCol[excited] -> nan\n",
      "DepselectCol[calm] -> nan\n",
      "DepselectCol[hopeful] -> Y\n",
      "DepselectCol[down] -> nan\n",
      "DepselectCol[anxious] -> nan\n",
      "DepselectCol[unhappy] -> nan\n",
      "DepselectCol[worried] -> nan\n",
      "DepselectCol[optimistic] -> nan\n",
      "DepselectCol[blue] -> nan\n",
      "DepselectCol[lonely] -> nan\n",
      "DepselectCol[relaxed] -> Y\n",
      "DepselectCol[pleased] -> nan\n",
      "DepselectCol[stressed] -> nan\n",
      "DepselectCol[depressed] -> nan\n",
      "DepselectCol[active] -> Y\n",
      "DepselectCol[angry] -> nan\n",
      "DepselectCol[fun] -> nan\n",
      "DepselectCol[loving] -> nan\n",
      "DepselectCol[upbeat] -> nan\n",
      "DepselectCol[blessed] -> nan\n",
      "DepselectCol[joy] -> nan\n",
      "DepselectCol[love] -> nan\n",
      "DepselectCol[loved] -> nan\n",
      "WorselectCol[anxious] -> nan\n",
      "WorselectCol[calm] -> nan\n",
      "WorselectCol[happy] -> Y\n",
      "WorselectCol[nervous] -> nan\n",
      "WorselectCol[relaxed] -> nan\n",
      "WorselectCol[concerned] -> nan\n",
      "WorselectCol[worried] -> nan\n",
      "WorselectCol[content] -> nan\n",
      "WorselectCol[stressed] -> nan\n",
      "WorselectCol[peaceful] -> nan\n",
      "WorselectCol[upset] -> nan\n",
      "WorselectCol[tense] -> nan\n",
      "WorselectCol[scared] -> nan\n",
      "WorselectCol[carefree] -> Y\n",
      "WorselectCol[uneasy] -> nan\n",
      "WorselectCol[fearful] -> nan\n",
      "WorselectCol[hopeful] -> nan\n",
      "WorselectCol[sad] -> nan\n",
      "WorselectCol[satisfied] -> Y\n",
      "WorselectCol[stress] -> nan\n",
      "WorselectCol[money] -> nan\n",
      "WorselectCol[anxiety] -> nan\n",
      "WorselectCol[fear] -> nan\n",
      "WorselectCol[tired] -> nan\n",
      "WorselectCol[unworried] -> nan\n",
      "WorselectCol[troubled] -> nan\n",
      "WorselectCol[confident] -> Y\n",
      "WorselectCol[thoughtful] -> nan\n",
      "WorselectCol[bothered] -> nan\n",
      "WorselectCol[peace] -> Y\n",
      "WorselectCol[untroubled] -> nan\n",
      "PHQ[SQ01] -> 0.0\n",
      "PHQ[SQ02] -> 0.0\n",
      "PHQ[SQ03] -> 0.0\n",
      "PHQ[SQ04] -> 0.0\n",
      "PHQ[SQ05] -> 0.0\n",
      "PHQ[SQ06] -> 0.0\n",
      "PHQ[SQ07] -> 0.0\n",
      "PHQ[SQ08] -> 0.0\n",
      "PHQ[SQ09] -> 0.0\n",
      "PHQ[SQ10] -> 2.0\n",
      "PHQextra -> nan\n",
      "CESD[SQ01] -> 0.0\n",
      "CESD[SQ02] -> 0.0\n",
      "CESD[SQ03] -> 0.0\n",
      "CESD[SQ04] -> 3.0\n",
      "CESD[SQ05] -> 0.0\n",
      "CESD[SQ06] -> 0.0\n",
      "CESD[SQ07] -> 0.0\n",
      "CESD[SQ08] -> 3.0\n",
      "CESD[SQ09] -> 0.0\n",
      "CESD[SQ10] -> 0.0\n",
      "CESD[SQ11] -> 0.0\n",
      "CESD[SQ12] -> 3.0\n",
      "CESD[SQ13] -> 0.0\n",
      "CESD[SQ14] -> 0.0\n",
      "CESD[SQ15] -> 0.0\n",
      "CESD[SQ16] -> 2.0\n",
      "CESD[SQ17] -> 0.0\n",
      "CESD[SQ18] -> 0.0\n",
      "CESD[SQ19] -> 0.0\n",
      "CESD[SQ20] -> 0.0\n",
      "GADsurvey[SQ01] -> 0.0\n",
      "GADsurvey[SQ02] -> 0.0\n",
      "GADsurvey[SQ03] -> 0.0\n",
      "GADsurvey[SQ04] -> 0.0\n",
      "GADsurvey[SQ05] -> 0.0\n",
      "GADsurvey[SQ06] -> 1.0\n",
      "GADsurvey[SQ07] -> 0.0\n",
      "GADsurvey[SQ08] -> 1.0\n",
      "GADextra -> 0.0\n",
      "PSWQsurvey[SQ01] -> 3.0\n",
      "PSWQsurvey[SQ02] -> 1.0\n",
      "PSWQsurvey[SQ03] -> 3.0\n",
      "PSWQsurvey[SQ04] -> 1.0\n",
      "PSWQsurvey[SQ05] -> 1.0\n",
      "PSWQsurvey[SQ06] -> 2.0\n",
      "PSWQsurvey[SQ07] -> 1.0\n",
      "PSWQsurvey[SQ08] -> 3.0\n",
      "PSWQsurvey[SQ09] -> 1.0\n",
      "PSWQsurvey[SQ10] -> 3.0\n",
      "PSWQsurvey[SQ11] -> 3.0\n",
      "PSWQsurvey[SQ12] -> 1.0\n",
      "PSWQsurvey[SQ13] -> 2.0\n",
      "PSWQsurvey[SQ14] -> 1.0\n",
      "PSWQsurvey[SQ15] -> 1.0\n",
      "PSWQsurvey[SQ16] -> 1.0\n",
      "A1 -> 0.0\n",
      "A2 -> 0.0\n",
      "A3a -> 0\n",
      "A3b1 -> 0\n",
      "A3c1 -> 0\n",
      "A3d1 -> 0\n",
      "A3e1 -> 0\n",
      "A3f1 -> 0\n",
      "A3g1 -> 0\n",
      "A4a -> nan\n",
      "A5 -> nan\n",
      "A6 -> nan\n",
      "N1a -> 0\n",
      "N1a2 -> 0\n",
      "N1b -> 0\n",
      "N2 -> 0\n",
      "N3a -> 0\n",
      "N3b -> 0\n",
      "N3c -> 0\n",
      "N3d -> 0\n",
      "N3e -> 0\n",
      "N3f -> 0\n",
      "N4 -> 0\n",
      "Diagnosis[SQ01] -> nan\n",
      "Diagnosis[SQ02] -> nan\n",
      "Diagnosis[SQ03] -> nan\n",
      "Diagnosis[SQ04] -> Y\n",
      "SickDaysMonth -> 0.0\n",
      "MentalSickDays -> 0.0\n",
      "SickDaysYear -> 0.0\n",
      "MentalSickDaysYear -> 0.0\n",
      "HealthCareVisits -> 0.0\n",
      "HealthCareMental -> 0.0\n",
      "Treatment[SQ01] -> Y\n",
      "Treatment[SQ02] -> nan\n",
      "Treatment[SQ03] -> nan\n",
      "Treatment[SQ04] -> nan\n",
      "Treatment[other] -> nan\n",
      "Gender -> 1.0\n",
      "Age -> 30.0\n",
      "interviewtime -> nan\n",
      "ProlificIDTime -> nan\n",
      "sequence1Time -> nan\n",
      "seqOneTime -> nan\n",
      "Dep5wordsTime -> nan\n",
      "Wor5wordsTime -> nan\n",
      "sequence2Time -> nan\n",
      "seq2Time -> nan\n",
      "Dep5phraseorwordsTime -> nan\n",
      "Wor5phraseorwordsTime -> nan\n",
      "sequence3Time -> nan\n",
      "seq3Time -> nan\n",
      "DeptextTime -> nan\n",
      "WortextTime -> nan\n",
      "DepselectColTime -> nan\n",
      "WorselectColTime -> nan\n",
      "PHQTime -> nan\n",
      "PHQextraTime -> nan\n",
      "CESDTime -> nan\n",
      "GADsurveyTime -> nan\n",
      "GADextraTime -> nan\n",
      "PSWQsurveyTime -> nan\n",
      "A1Time -> nan\n",
      "A2Time -> nan\n",
      "A3aTime -> nan\n",
      "A3b1Time -> nan\n",
      "A3c1Time -> nan\n",
      "A3d1Time -> nan\n",
      "A3e1Time -> nan\n",
      "A3f1Time -> nan\n",
      "A3g1Time -> nan\n",
      "A4aTime -> nan\n",
      "A5Time -> nan\n",
      "A6Time -> nan\n",
      "N1aTime -> nan\n",
      "N1a2Time -> nan\n",
      "N1bTime -> nan\n",
      "N2Time -> nan\n",
      "N3aTime -> nan\n",
      "N3bTime -> nan\n",
      "N3cTime -> nan\n",
      "N3dTime -> nan\n",
      "N3eTime -> nan\n",
      "N3fTime -> nan\n",
      "N4Time -> nan\n",
      "DiagnosisTime -> nan\n",
      "SickDaysMonthTime -> nan\n",
      "MentalSickDaysTime -> nan\n",
      "SickDaysYearTime -> nan\n",
      "MentalSickDaysYearTime -> nan\n",
      "HealthCareVisitsTime -> nan\n",
      "HealthCareMentalTime -> nan\n",
      "TreatmentTime -> nan\n",
      "GenderTime -> nan\n",
      "AgeTime -> nan\n",
      "session_id -> 5f2d3ce80659d02a3948e4dc\n",
      "status -> APPROVED\n",
      "started_datetime -> 2020-08-07 11:37:52\n",
      "completed_date_time -> 2020-08-07 11:46:41\n",
      "time_taken -> 529.155\n",
      "age -> 33.0\n",
      "num_approvals -> 1651.0\n",
      "num_rejections -> 1.0\n",
      "prolific_score -> 100.0\n",
      "reviewed_at_datetime -> 2020-08-07 17:36:19\n",
      "entered_code -> 4536C388\n",
      "Country of Birth -> United States\n",
      "Current Country of Residence -> United States\n",
      "Employment Status -> DATA EXPIRED\n",
      "First Language -> English\n",
      "Nationality -> United States\n",
      "Sex -> Male\n",
      "Student Status -> DATA EXPIRED\n",
      "PHQ1 -> 0.0\n",
      "PHQ2 -> 0.0\n",
      "PHQ3 -> 0.0\n",
      "PHQ4 -> 0.0\n",
      "PHQ5 -> 0.0\n",
      "PHQ6 -> 0.0\n",
      "PHQ7 -> 0.0\n",
      "PHQ8 -> 0.0\n",
      "PHQ9 -> 0.0\n",
      "PHQ_control2 -> 2.0\n",
      "CESD1 -> 0.0\n",
      "CESD2 -> 0.0\n",
      "CESD3 -> 0.0\n",
      "CESD4 -> 3.0\n",
      "CESD5 -> 0.0\n",
      "CESD6 -> 0.0\n",
      "CESD7 -> 0.0\n",
      "CESD8 -> 3.0\n",
      "CESD9 -> 0.0\n",
      "CESD10 -> 0.0\n",
      "CESD11 -> 0.0\n",
      "CESD12 -> 3.0\n",
      "CESD13 -> 0.0\n",
      "CESD14 -> 0.0\n",
      "CESD15 -> 0.0\n",
      "CESD16 -> 2.0\n",
      "CESD17 -> 0.0\n",
      "CESD18 -> 0.0\n",
      "CESD19 -> 0.0\n",
      "CESD20 -> 0.0\n",
      "GAD1 -> 0.0\n",
      "GAD2 -> 0.0\n",
      "GAD3 -> 0.0\n",
      "GAD4 -> 0.0\n",
      "GAD5 -> 0.0\n",
      "GAD6 -> 1.0\n",
      "GAD7 -> 0.0\n",
      "GADcontrol1 -> 1.0\n",
      "PSWQ1 -> 3.0\n",
      "PSWQ2 -> 1.0\n",
      "PSWQ3 -> 3.0\n",
      "PSWQ4 -> 1.0\n",
      "PSWQ5 -> 1.0\n",
      "PSWQ6 -> 2.0\n",
      "PSWQ7 -> 1.0\n",
      "PSWQ8 -> 3.0\n",
      "PSWQ9 -> 1.0\n",
      "PSWQ10 -> 3.0\n",
      "PSWQ11 -> 3.0\n",
      "PSWQ12 -> 1.0\n",
      "PSWQ13 -> 2.0\n",
      "PSWQ14 -> 1.0\n",
      "PSWQ15 -> 1.0\n",
      "PSWQ16 -> 1.0\n",
      "PHQtot -> 0.0\n",
      "GADtot -> 1.0\n",
      "PSWQtot -> 10.0\n",
      "CESD4rev -> 0.0\n",
      "CESD8rev -> 0.0\n",
      "CESD12rev -> 0.0\n",
      "CESD16rev -> 1.0\n",
      "CESDtot -> 1.0\n",
      "dep_all_words -> motivated learning passionate enthusiastic happy\n",
      "wor_all_words -> motivated enthusiastic learning exercise nutrition\n",
      "dep_all_phraces -> happy eager to learn restful sleep motivated joyful\n",
      "wor_all_phraces -> content improving learning motivated better than before\n",
      "dep_text -> Over the past two weeks, I have not been depressed.  I have been interested in things as much as I normally have been.  I have been in a good mood and I have been motivated to do things.  I have been engaged in my normal activities and my sleep has been pretty good.\n",
      "wor_text -> Over the last two weeks, I have not been worried.  I am not worried about coronavirus, because I am working from home and take all the necessary precautions.  Things have been going my way recently and I have been making a lot of things happening.\n",
      "DepselectCol_happy -> nan\n",
      "DepselectCol_sad -> nan\n",
      "DepselectCol_content -> nan\n",
      "DepselectCol_joyful -> joyful\n",
      "DepselectCol_satisfied -> nan\n",
      "DepselectCol_tired -> nan\n",
      "DepselectCol_peaceful -> nan\n",
      "DepselectCol_cheerful -> cheerful\n",
      "DepselectCol_excited -> nan\n",
      "DepselectCol_calm -> nan\n",
      "DepselectCol_hopeful -> hopeful\n",
      "DepselectCol_down -> nan\n",
      "DepselectCol_anxious -> nan\n",
      "DepselectCol_unhappy -> nan\n",
      "DepselectCol_worried -> nan\n",
      "DepselectCol_optimistic -> nan\n",
      "DepselectCol_blue -> nan\n",
      "DepselectCol_lonely -> nan\n",
      "DepselectCol_relaxed -> relaxed\n",
      "DepselectCol_pleased -> nan\n",
      "DepselectCol_stressed -> nan\n",
      "DepselectCol_depressed -> nan\n",
      "DepselectCol_active -> active\n",
      "DepselectCol_angry -> nan\n",
      "DepselectCol_fun -> nan\n",
      "DepselectCol_loving -> nan\n",
      "DepselectCol_upbeat -> nan\n",
      "DepselectCol_blessed -> nan\n",
      "DepselectCol_joy -> nan\n",
      "DepselectCol_love -> nan\n",
      "dep_all_selected -> NA NA NA joyful NA NA NA cheerful NA NA hopeful NA NA NA NA NA NA NA relaxed NA NA NA active NA NA NA NA NA NA NA\n",
      "dep_all_selected1 ->    joyful    cheerful   hopeful        relaxed    active       \n",
      "WorselectCol_anxious -> nan\n",
      "WorselectCol_calm -> nan\n",
      "WorselectCol_happy -> happy\n",
      "WorselectCol_nervous -> nan\n",
      "WorselectCol_relaxed -> nan\n",
      "WorselectCol_concerned -> nan\n",
      "WorselectCol_worried -> nan\n",
      "WorselectCol_content -> nan\n",
      "WorselectCol_stressed -> nan\n",
      "WorselectCol_peaceful -> nan\n",
      "WorselectCol_upset -> nan\n",
      "WorselectCol_tense -> nan\n",
      "WorselectCol_scared -> nan\n",
      "WorselectCol_carefree -> carefree\n",
      "WorselectCol_uneasy -> nan\n",
      "WorselectCol_fearful -> nan\n",
      "WorselectCol_hopeful -> nan\n",
      "WorselectCol_sad -> nan\n",
      "WorselectCol_satisfied -> satisfied\n",
      "WorselectCol_stress -> nan\n",
      "WorselectCol_money -> nan\n",
      "WorselectCol_anxiety -> nan\n",
      "WorselectCol_fear -> nan\n",
      "WorselectCol_tired -> nan\n",
      "WorselectCol_unworried -> nan\n",
      "WorselectCol_troubled -> nan\n",
      "WorselectCol_confident -> confident\n",
      "WorselectCol_thoughtful -> nan\n",
      "WorselectCol_bothered -> nan\n",
      "WorselectCol_peace -> peace\n",
      "WorselectCol_untroubled -> nan\n",
      "wor_all_selected -> NA NA happy NA NA NA NA NA NA NA NA NA NA carefree NA NA NA NA satisfied NA NA NA NA NA NA NA confident NA NA peace NA\n",
      "wor_all_selected1 ->   happy           carefree     satisfied        confident   peace \n",
      "minidep_scale -> 0.0\n",
      "minidep_diagnose -> 0\n",
      "depression_episodes -> 0\n",
      "miniGAD_scale -> 0\n",
      "miniGAD_symptoms_scale -> 0\n",
      "miniGAD_diagnose -> 0\n",
      "minidiagnose_category -> NoDi\n",
      "minidiagnose_category_number -> 0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Only for understanding data and visualize a response example.\n",
    "Prints column name and response of patient at row 0.\n",
    "\"\"\"\n",
    "for res, col in zip(responses.iloc[0], responses.columns):\n",
    "    print(\"{} -> {}\".format(col, res))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing and cleaning semantic space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using 5-gram contexts from the database, a co-occurrence (word by word) matrix was set up, \n",
    "where the rows contained the 120,000 most common words in the n-gram database and the columns \n",
    "consisted of the 10,000 most common words in the n-gram database.\n",
    "\n",
    "The variable 'space' is a matrix of the semantic space with dimentions reduced to 512.\n",
    "\"\"\"\n",
    "path = os.path.join(os.getcwd(), 'data', 'spaceEnglish1.csv')\n",
    "space = pd.read_csv(path, encoding= 'unicode_escape')\n",
    "space.set_index('words', inplace=True)\n",
    "space.drop(space.columns[[0]], axis=1, inplace=True)\n",
    "space.dropna(inplace=True)\n",
    "space = space[~space.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X503</th>\n",
       "      <th>X504</th>\n",
       "      <th>X505</th>\n",
       "      <th>X506</th>\n",
       "      <th>X507</th>\n",
       "      <th>X508</th>\n",
       "      <th>X509</th>\n",
       "      <th>X510</th>\n",
       "      <th>X511</th>\n",
       "      <th>X512</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>-0.234071</td>\n",
       "      <td>-0.278211</td>\n",
       "      <td>-0.100658</td>\n",
       "      <td>-0.269570</td>\n",
       "      <td>-0.115498</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.036835</td>\n",
       "      <td>0.024037</td>\n",
       "      <td>-0.003974</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011414</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>-0.020312</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>0.012867</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>-0.020382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>-0.283230</td>\n",
       "      <td>-0.338776</td>\n",
       "      <td>-0.141085</td>\n",
       "      <td>-0.243715</td>\n",
       "      <td>-0.236692</td>\n",
       "      <td>-0.033354</td>\n",
       "      <td>-0.099906</td>\n",
       "      <td>0.053253</td>\n",
       "      <td>-0.025582</td>\n",
       "      <td>-0.040372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028472</td>\n",
       "      <td>0.048824</td>\n",
       "      <td>-0.025452</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.027658</td>\n",
       "      <td>-0.022135</td>\n",
       "      <td>0.023037</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>-0.001482</td>\n",
       "      <td>-0.024063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>-0.251058</td>\n",
       "      <td>-0.327183</td>\n",
       "      <td>-0.203889</td>\n",
       "      <td>-0.283337</td>\n",
       "      <td>-0.124522</td>\n",
       "      <td>-0.006537</td>\n",
       "      <td>0.015371</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>-0.130597</td>\n",
       "      <td>0.055605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>-0.012646</td>\n",
       "      <td>-0.005019</td>\n",
       "      <td>0.075544</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>-0.022636</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>-0.027951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>-0.281888</td>\n",
       "      <td>-0.346746</td>\n",
       "      <td>-0.171006</td>\n",
       "      <td>-0.266698</td>\n",
       "      <td>-0.208917</td>\n",
       "      <td>-0.019832</td>\n",
       "      <td>-0.035404</td>\n",
       "      <td>0.044301</td>\n",
       "      <td>-0.076601</td>\n",
       "      <td>0.021328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019319</td>\n",
       "      <td>0.042742</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.034352</td>\n",
       "      <td>0.033282</td>\n",
       "      <td>-0.006843</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>-0.013623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.256530</td>\n",
       "      <td>-0.335434</td>\n",
       "      <td>-0.229791</td>\n",
       "      <td>-0.256070</td>\n",
       "      <td>-0.120020</td>\n",
       "      <td>0.017080</td>\n",
       "      <td>0.078004</td>\n",
       "      <td>0.112134</td>\n",
       "      <td>-0.073805</td>\n",
       "      <td>0.098183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>-0.022383</td>\n",
       "      <td>-0.042172</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.013435</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>-0.022769</td>\n",
       "      <td>0.024873</td>\n",
       "      <td>0.010061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X1        X2        X3        X4        X5        X6        X7  \\\n",
       "words                                                                         \n",
       "was   -0.234071 -0.278211 -0.100658 -0.269570 -0.115498 -0.000038 -0.036835   \n",
       "not   -0.283230 -0.338776 -0.141085 -0.243715 -0.236692 -0.033354 -0.099906   \n",
       "by    -0.251058 -0.327183 -0.203889 -0.283337 -0.124522 -0.006537  0.015371   \n",
       "that  -0.281888 -0.346746 -0.171006 -0.266698 -0.208917 -0.019832 -0.035404   \n",
       "of    -0.256530 -0.335434 -0.229791 -0.256070 -0.120020  0.017080  0.078004   \n",
       "\n",
       "             X8        X9       X10  ...      X503      X504      X505  \\\n",
       "words                                ...                                 \n",
       "was    0.024037 -0.003974  0.006582  ... -0.011414  0.018075 -0.020312   \n",
       "not    0.053253 -0.025582 -0.040372  ... -0.028472  0.048824 -0.025452   \n",
       "by     0.131667 -0.130597  0.055605  ... -0.001550  0.027915 -0.012646   \n",
       "that   0.044301 -0.076601  0.021328  ...  0.019319  0.042742  0.001747   \n",
       "of     0.112134 -0.073805  0.098183  ...  0.012012  0.005470 -0.022383   \n",
       "\n",
       "           X506      X507      X508      X509      X510      X511      X512  \n",
       "words                                                                        \n",
       "was    0.001287  0.024483  0.012867  0.021265  0.016368  0.024858 -0.020382  \n",
       "not    0.007828  0.027658 -0.022135  0.023037  0.005371 -0.001482 -0.024063  \n",
       "by    -0.005019  0.075544  0.014663  0.013489 -0.022636  0.010127 -0.027951  \n",
       "that   0.019198  0.022598  0.034352  0.033282 -0.006843  0.027052 -0.013623  \n",
       "of    -0.042172 -0.003430 -0.013435  0.003697 -0.022769  0.024873  0.010061  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Methods for cleaning and aggregating semantic responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleans the string from punctuations and removes all words which are not represented in the semantic space. \n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import math\n",
    "\n",
    "words_in_space = set(space.index.values)\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        try:\n",
    "            text = text.lower()\n",
    "            text = re.sub(r'[^\\w\\s]', '', text)\n",
    "            text = list(set(text.split()))\n",
    "            cleaned_words = [w for w in text if w in words_in_space] # TODO: Hantera ord som inte finns i spacet. Nu ignoreras dem.\n",
    "            return cleaned_words\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    elif math.isnan(text):\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Controlling for artifacts relating to frequently occurring words.\n",
    "\n",
    "1) Calculate, from Google N-gram, a frequency weighted average of all semantic representations in the space.\n",
    "   (So that the weighting is proportional to how frequently the words occur in Google N-gram.)\n",
    "2) Subtract this mean prior to aggregating each word, and then add to the final value.\n",
    "\"\"\"\n",
    "\n",
    "space_mean = pd.Series.to_numpy(space.mean())\n",
    "\n",
    "def aggregating_words(responses):\n",
    "    res_arr = np.zeros(512)\n",
    "    \n",
    "    for word in responses:\n",
    "        word_arr = pd.Series.to_numpy(space.loc[word])\n",
    "        res_arr = res_arr + (word_arr - space_mean)\n",
    "    \n",
    "    res_arr += space_mean    \n",
    "    res_arr = res_arr / res_arr.sum() # Normalizing aggregated vector\n",
    "    return res_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_cell(text):\n",
    "    words_in_cell = pd.Series.apply(text, clean_text)\n",
    "    cell_vectors = pd.Series.apply(words_in_cell, aggregating_words)\n",
    "    return cell_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting semantic responses and representing the answer to each question in the semantic space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_columns = ['Deptext', 'dep_all_phraces', 'dep_all_words', 'dep_all_selected1']\n",
    "df_dep_responses = responses[dep_columns]\n",
    "\n",
    "df_dep_aggregated = df_dep_responses.apply(aggregate_cell, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wor_columns = ['Wortext', 'wor_all_phraces', 'wor_all_words', 'wor_all_selected1']\n",
    "df_wor_responses = responses[wor_columns]\n",
    "\n",
    "df_wor_aggregated = df_wor_responses.apply(aggregate_cell, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deptext</th>\n",
       "      <th>dep_all_phraces</th>\n",
       "      <th>dep_all_words</th>\n",
       "      <th>dep_all_selected1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.14620488346512744, 0.20439917711775296, 0.0...</td>\n",
       "      <td>[-0.7590918166513154, -0.7996448245182239, 0.6...</td>\n",
       "      <td>[-0.12735496139054883, -0.08134255488745973, 0...</td>\n",
       "      <td>[-0.10631367041145826, -0.07611765664843519, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.16873259944807936, 0.22817746128469954, -0....</td>\n",
       "      <td>[0.3150959567419946, 0.42077095201920844, 0.01...</td>\n",
       "      <td>[1.4817085495650797, 1.6852794755670606, -1.02...</td>\n",
       "      <td>[-0.44645774520185744, -0.3896723426287449, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.15851603167923162, 0.217751607989601, 0.031...</td>\n",
       "      <td>[0.09205027035822107, 0.12041302636339309, 0.0...</td>\n",
       "      <td>[0.12709153308204268, 0.14295118020024072, -0....</td>\n",
       "      <td>[-0.07663349903279247, -0.0006333442681840848,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.15762474074250946, 0.2167201417841256, 0.02...</td>\n",
       "      <td>[0.2704033968315661, 0.35429957613545476, -0.0...</td>\n",
       "      <td>[0.025633109762595925, 0.008765453890638987, -...</td>\n",
       "      <td>[-0.07360932328901602, -0.0390370122596679, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.19196984693977662, 0.26635971533780406, 0.0...</td>\n",
       "      <td>[0.39916260826011746, 0.4636167724424405, -0.1...</td>\n",
       "      <td>[0.10400074631268061, 0.11652565658484358, -0....</td>\n",
       "      <td>[53.497985284343585, 36.203814272227355, -104....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.16020033435596975, 0.2247685690990484, 0.03...</td>\n",
       "      <td>[0.4163829239997853, 0.5368902458559512, -0.04...</td>\n",
       "      <td>[-0.026319931002123518, -0.008734687972281292,...</td>\n",
       "      <td>[-0.09433512754889448, -0.049385819397829094, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.24168212896922367, 0.33902324777852244, 0.0...</td>\n",
       "      <td>[0.13731923979741936, 0.1772812205588881, 0.03...</td>\n",
       "      <td>[-0.2157567390391844, -0.17254878886225866, 0....</td>\n",
       "      <td>[-0.07639443687669704, -0.06505044300142826, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.1974876347513036, 0.269650876661491, 0.0217...</td>\n",
       "      <td>[0.13360152439614426, 0.1815627422093893, 0.02...</td>\n",
       "      <td>[-0.19561638585825614, -0.14930168873878913, 0...</td>\n",
       "      <td>[0.28285568876115935, 0.25211172678271115, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.20163162925816505, 0.2766626351045351, 0.00...</td>\n",
       "      <td>[-0.45676491421319454, -0.1752281301733496, 0....</td>\n",
       "      <td>[-0.1390705297657966, -0.08380077038092038, 0....</td>\n",
       "      <td>[-2.0148557305068096, -1.7268435631282695, 3.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.16036779308098767, 0.22456358894876235, 0.0...</td>\n",
       "      <td>[0.23138802445768988, 0.3189740213924604, 0.02...</td>\n",
       "      <td>[-0.37102690646248687, -0.38723656128234035, 0...</td>\n",
       "      <td>[-0.2317635994266962, -0.2015510492531911, 0.2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Deptext  \\\n",
       "0  [0.14620488346512744, 0.20439917711775296, 0.0...   \n",
       "1  [0.16873259944807936, 0.22817746128469954, -0....   \n",
       "2  [0.15851603167923162, 0.217751607989601, 0.031...   \n",
       "3  [0.15762474074250946, 0.2167201417841256, 0.02...   \n",
       "4  [0.19196984693977662, 0.26635971533780406, 0.0...   \n",
       "5  [0.16020033435596975, 0.2247685690990484, 0.03...   \n",
       "6  [0.24168212896922367, 0.33902324777852244, 0.0...   \n",
       "7  [0.1974876347513036, 0.269650876661491, 0.0217...   \n",
       "8  [0.20163162925816505, 0.2766626351045351, 0.00...   \n",
       "9  [0.16036779308098767, 0.22456358894876235, 0.0...   \n",
       "\n",
       "                                     dep_all_phraces  \\\n",
       "0  [-0.7590918166513154, -0.7996448245182239, 0.6...   \n",
       "1  [0.3150959567419946, 0.42077095201920844, 0.01...   \n",
       "2  [0.09205027035822107, 0.12041302636339309, 0.0...   \n",
       "3  [0.2704033968315661, 0.35429957613545476, -0.0...   \n",
       "4  [0.39916260826011746, 0.4636167724424405, -0.1...   \n",
       "5  [0.4163829239997853, 0.5368902458559512, -0.04...   \n",
       "6  [0.13731923979741936, 0.1772812205588881, 0.03...   \n",
       "7  [0.13360152439614426, 0.1815627422093893, 0.02...   \n",
       "8  [-0.45676491421319454, -0.1752281301733496, 0....   \n",
       "9  [0.23138802445768988, 0.3189740213924604, 0.02...   \n",
       "\n",
       "                                       dep_all_words  \\\n",
       "0  [-0.12735496139054883, -0.08134255488745973, 0...   \n",
       "1  [1.4817085495650797, 1.6852794755670606, -1.02...   \n",
       "2  [0.12709153308204268, 0.14295118020024072, -0....   \n",
       "3  [0.025633109762595925, 0.008765453890638987, -...   \n",
       "4  [0.10400074631268061, 0.11652565658484358, -0....   \n",
       "5  [-0.026319931002123518, -0.008734687972281292,...   \n",
       "6  [-0.2157567390391844, -0.17254878886225866, 0....   \n",
       "7  [-0.19561638585825614, -0.14930168873878913, 0...   \n",
       "8  [-0.1390705297657966, -0.08380077038092038, 0....   \n",
       "9  [-0.37102690646248687, -0.38723656128234035, 0...   \n",
       "\n",
       "                                   dep_all_selected1  \n",
       "0  [-0.10631367041145826, -0.07611765664843519, 0...  \n",
       "1  [-0.44645774520185744, -0.3896723426287449, 0....  \n",
       "2  [-0.07663349903279247, -0.0006333442681840848,...  \n",
       "3  [-0.07360932328901602, -0.0390370122596679, 0....  \n",
       "4  [53.497985284343585, 36.203814272227355, -104....  \n",
       "5  [-0.09433512754889448, -0.049385819397829094, ...  \n",
       "6  [-0.07639443687669704, -0.06505044300142826, 0...  \n",
       "7  [0.28285568876115935, 0.25211172678271115, -0....  \n",
       "8  [-2.0148557305068096, -1.7268435631282695, 3.1...  \n",
       "9  [-0.2317635994266962, -0.2015510492531911, 0.2...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dep_aggregated.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wortext</th>\n",
       "      <th>wor_all_phraces</th>\n",
       "      <th>wor_all_words</th>\n",
       "      <th>wor_all_selected1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.14898981572633896, 0.20678471111840982, 0.0...</td>\n",
       "      <td>[0.16848163704578217, 0.21104085954673169, 0.0...</td>\n",
       "      <td>[0.08512889256007851, 0.06930940294720918, -0....</td>\n",
       "      <td>[-0.03628907508059879, -0.028415450913131562, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.16658035037273553, 0.22419803669426439, -0....</td>\n",
       "      <td>[2.926113550483023, 3.7758155740939063, -0.291...</td>\n",
       "      <td>[-0.5054823889786438, -0.17190850524640067, 0....</td>\n",
       "      <td>[-0.04345398189988287, -0.020184341988825117, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.14912997482144708, 0.20770588773293341, 0.0...</td>\n",
       "      <td>[0.1066276252125093, 0.12498854698322402, -0.0...</td>\n",
       "      <td>[0.07113400315024147, 0.0740523236751316, -0.0...</td>\n",
       "      <td>[-0.2445014187941481, -0.12076884155682258, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.14166991480328242, 0.19702991519885332, 0.0...</td>\n",
       "      <td>[-0.20939610364178599, -0.022625746545145924, ...</td>\n",
       "      <td>[-0.06529720047146925, 0.046267332309029886, 0...</td>\n",
       "      <td>[-0.1487217599810065, -0.09152232772736152, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.1867096354427328, 0.25676537028535223, 0.02...</td>\n",
       "      <td>[0.2684734403529659, 0.3316357580608248, 0.000...</td>\n",
       "      <td>[-0.08879341781163712, -0.0742497412666487, 0....</td>\n",
       "      <td>[-0.06327165709289424, -0.041942097040231, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.2411979563481076, 0.3323859887436077, 0.034...</td>\n",
       "      <td>[0.46890125346292655, 0.587621833904448, -0.04...</td>\n",
       "      <td>[-0.30424776300405115, -0.0494967160663658, 0....</td>\n",
       "      <td>[-0.041991902728896614, -0.024059956123692577,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.2436212877690359, 0.336328680492232, 0.0172...</td>\n",
       "      <td>[0.14751288417729555, 0.19693854765932112, 0.0...</td>\n",
       "      <td>[0.11098324236286283, 0.03640903903022074, -0....</td>\n",
       "      <td>[0.3334432322058593, 0.2695373227264273, -0.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.1685784496444126, 0.23540663423371672, 0.03...</td>\n",
       "      <td>[0.15824374599203708, 0.20497218134088446, -0....</td>\n",
       "      <td>[-0.26178040246623874, 0.007203681762336984, 0...</td>\n",
       "      <td>[0.0637826975260297, 0.008016117756634647, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.1852202116778388, 0.2544669083751666, 0.008...</td>\n",
       "      <td>[0.1163590562232893, 0.01858513322123727, -0.3...</td>\n",
       "      <td>[0.06984923510555666, 0.0065180639121360994, -...</td>\n",
       "      <td>[0.08754686825446148, 0.06462605258728954, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.2046066832838274, 0.28211646776321414, 0.02...</td>\n",
       "      <td>[0.1755492642411605, 0.2157095366202667, -0.03...</td>\n",
       "      <td>[-0.10305678157119322, -0.046450255936402285, ...</td>\n",
       "      <td>[-0.3179574394075049, -0.17534088139707735, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Wortext  \\\n",
       "0  [0.14898981572633896, 0.20678471111840982, 0.0...   \n",
       "1  [0.16658035037273553, 0.22419803669426439, -0....   \n",
       "2  [0.14912997482144708, 0.20770588773293341, 0.0...   \n",
       "3  [0.14166991480328242, 0.19702991519885332, 0.0...   \n",
       "4  [0.1867096354427328, 0.25676537028535223, 0.02...   \n",
       "5  [0.2411979563481076, 0.3323859887436077, 0.034...   \n",
       "6  [0.2436212877690359, 0.336328680492232, 0.0172...   \n",
       "7  [0.1685784496444126, 0.23540663423371672, 0.03...   \n",
       "8  [0.1852202116778388, 0.2544669083751666, 0.008...   \n",
       "9  [0.2046066832838274, 0.28211646776321414, 0.02...   \n",
       "\n",
       "                                     wor_all_phraces  \\\n",
       "0  [0.16848163704578217, 0.21104085954673169, 0.0...   \n",
       "1  [2.926113550483023, 3.7758155740939063, -0.291...   \n",
       "2  [0.1066276252125093, 0.12498854698322402, -0.0...   \n",
       "3  [-0.20939610364178599, -0.022625746545145924, ...   \n",
       "4  [0.2684734403529659, 0.3316357580608248, 0.000...   \n",
       "5  [0.46890125346292655, 0.587621833904448, -0.04...   \n",
       "6  [0.14751288417729555, 0.19693854765932112, 0.0...   \n",
       "7  [0.15824374599203708, 0.20497218134088446, -0....   \n",
       "8  [0.1163590562232893, 0.01858513322123727, -0.3...   \n",
       "9  [0.1755492642411605, 0.2157095366202667, -0.03...   \n",
       "\n",
       "                                       wor_all_words  \\\n",
       "0  [0.08512889256007851, 0.06930940294720918, -0....   \n",
       "1  [-0.5054823889786438, -0.17190850524640067, 0....   \n",
       "2  [0.07113400315024147, 0.0740523236751316, -0.0...   \n",
       "3  [-0.06529720047146925, 0.046267332309029886, 0...   \n",
       "4  [-0.08879341781163712, -0.0742497412666487, 0....   \n",
       "5  [-0.30424776300405115, -0.0494967160663658, 0....   \n",
       "6  [0.11098324236286283, 0.03640903903022074, -0....   \n",
       "7  [-0.26178040246623874, 0.007203681762336984, 0...   \n",
       "8  [0.06984923510555666, 0.0065180639121360994, -...   \n",
       "9  [-0.10305678157119322, -0.046450255936402285, ...   \n",
       "\n",
       "                                   wor_all_selected1  \n",
       "0  [-0.03628907508059879, -0.028415450913131562, ...  \n",
       "1  [-0.04345398189988287, -0.020184341988825117, ...  \n",
       "2  [-0.2445014187941481, -0.12076884155682258, 0....  \n",
       "3  [-0.1487217599810065, -0.09152232772736152, 0....  \n",
       "4  [-0.06327165709289424, -0.041942097040231, 0.1...  \n",
       "5  [-0.041991902728896614, -0.024059956123692577,...  \n",
       "6  [0.3334432322058593, 0.2695373227264273, -0.26...  \n",
       "7  [0.0637826975260297, 0.008016117756634647, -0....  \n",
       "8  [0.08754686825446148, 0.06462605258728954, -0....  \n",
       "9  [-0.3179574394075049, -0.17534088139707735, 0....  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wor_aggregated.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_vectors(row):\n",
    "    return np.concatenate(row.values).ravel()\n",
    "\n",
    "df_dep_concat = pd.DataFrame(list(df_dep_aggregated.apply(concat_vectors, axis=1)))\n",
    "df_wor_concat = pd.DataFrame(list(df_wor_aggregated.apply(concat_vectors, axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatinating the semantic representations for each question into one multidimensional response vector\n",
    "Each participant's semantic responses are now represented by two 2048 dimension vectors. \n",
    "One for depression-words and one for anxiety-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.14899</td>\n",
       "      <td>0.206785</td>\n",
       "      <td>0.023243</td>\n",
       "      <td>0.112792</td>\n",
       "      <td>0.074571</td>\n",
       "      <td>-0.008851</td>\n",
       "      <td>0.013691</td>\n",
       "      <td>-0.043377</td>\n",
       "      <td>0.014825</td>\n",
       "      <td>-0.008417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>-0.035797</td>\n",
       "      <td>0.019894</td>\n",
       "      <td>0.002703</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.029119</td>\n",
       "      <td>0.024678</td>\n",
       "      <td>0.048164</td>\n",
       "      <td>-0.010254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.16658</td>\n",
       "      <td>0.224198</td>\n",
       "      <td>-0.004458</td>\n",
       "      <td>0.113733</td>\n",
       "      <td>0.087324</td>\n",
       "      <td>-0.004111</td>\n",
       "      <td>0.010961</td>\n",
       "      <td>-0.010853</td>\n",
       "      <td>0.018607</td>\n",
       "      <td>-0.006320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040995</td>\n",
       "      <td>0.030989</td>\n",
       "      <td>0.062659</td>\n",
       "      <td>0.024890</td>\n",
       "      <td>0.012699</td>\n",
       "      <td>0.026413</td>\n",
       "      <td>-0.019568</td>\n",
       "      <td>-0.009488</td>\n",
       "      <td>-0.010183</td>\n",
       "      <td>0.028609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.14913</td>\n",
       "      <td>0.207706</td>\n",
       "      <td>0.032671</td>\n",
       "      <td>0.094477</td>\n",
       "      <td>0.078758</td>\n",
       "      <td>-0.005968</td>\n",
       "      <td>0.030490</td>\n",
       "      <td>-0.038519</td>\n",
       "      <td>0.021922</td>\n",
       "      <td>-0.024786</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189723</td>\n",
       "      <td>0.225984</td>\n",
       "      <td>-0.004859</td>\n",
       "      <td>0.033828</td>\n",
       "      <td>-0.060299</td>\n",
       "      <td>0.032765</td>\n",
       "      <td>0.060161</td>\n",
       "      <td>0.088519</td>\n",
       "      <td>-0.097915</td>\n",
       "      <td>0.075118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.14167</td>\n",
       "      <td>0.197030</td>\n",
       "      <td>0.028099</td>\n",
       "      <td>0.093292</td>\n",
       "      <td>0.078866</td>\n",
       "      <td>-0.010142</td>\n",
       "      <td>0.025955</td>\n",
       "      <td>-0.040232</td>\n",
       "      <td>0.016910</td>\n",
       "      <td>-0.006348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054622</td>\n",
       "      <td>0.051137</td>\n",
       "      <td>0.079480</td>\n",
       "      <td>-0.059947</td>\n",
       "      <td>-0.065747</td>\n",
       "      <td>0.134321</td>\n",
       "      <td>-0.017070</td>\n",
       "      <td>0.023734</td>\n",
       "      <td>0.068587</td>\n",
       "      <td>0.040797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.18671</td>\n",
       "      <td>0.256765</td>\n",
       "      <td>0.023149</td>\n",
       "      <td>0.118886</td>\n",
       "      <td>0.098646</td>\n",
       "      <td>-0.017863</td>\n",
       "      <td>0.022382</td>\n",
       "      <td>-0.038842</td>\n",
       "      <td>0.013801</td>\n",
       "      <td>-0.023079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028358</td>\n",
       "      <td>0.058178</td>\n",
       "      <td>0.012247</td>\n",
       "      <td>-0.027454</td>\n",
       "      <td>-0.035450</td>\n",
       "      <td>0.003896</td>\n",
       "      <td>-0.008417</td>\n",
       "      <td>0.008029</td>\n",
       "      <td>0.002994</td>\n",
       "      <td>0.041565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0         1         2         3         4         5         6     \\\n",
       "0  0.14899  0.206785  0.023243  0.112792  0.074571 -0.008851  0.013691   \n",
       "1  0.16658  0.224198 -0.004458  0.113733  0.087324 -0.004111  0.010961   \n",
       "2  0.14913  0.207706  0.032671  0.094477  0.078758 -0.005968  0.030490   \n",
       "3  0.14167  0.197030  0.028099  0.093292  0.078866 -0.010142  0.025955   \n",
       "4  0.18671  0.256765  0.023149  0.118886  0.098646 -0.017863  0.022382   \n",
       "\n",
       "       7         8         9     ...      2038      2039      2040      2041  \\\n",
       "0 -0.043377  0.014825 -0.008417  ...  0.009460  0.002733 -0.035797  0.019894   \n",
       "1 -0.010853  0.018607 -0.006320  ...  0.040995  0.030989  0.062659  0.024890   \n",
       "2 -0.038519  0.021922 -0.024786  ...  0.189723  0.225984 -0.004859  0.033828   \n",
       "3 -0.040232  0.016910 -0.006348  ...  0.054622  0.051137  0.079480 -0.059947   \n",
       "4 -0.038842  0.013801 -0.023079  ... -0.028358  0.058178  0.012247 -0.027454   \n",
       "\n",
       "       2042      2043      2044      2045      2046      2047  \n",
       "0  0.002703  0.011657  0.029119  0.024678  0.048164 -0.010254  \n",
       "1  0.012699  0.026413 -0.019568 -0.009488 -0.010183  0.028609  \n",
       "2 -0.060299  0.032765  0.060161  0.088519 -0.097915  0.075118  \n",
       "3 -0.065747  0.134321 -0.017070  0.023734  0.068587  0.040797  \n",
       "4 -0.035450  0.003896 -0.008417  0.008029  0.002994  0.041565  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wor_concat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing principal component analysis to reduce the number of dimensions for the concatinated semantic vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Standardizing the features\n",
    "X_dep = df_dep_concat.values\n",
    "X_wor = df_wor_concat.values\n",
    "\n",
    "X_dep = StandardScaler().fit_transform(X_dep)\n",
    "X_wor = StandardScaler().fit_transform(X_wor)\n",
    "\n",
    "pca = PCA(n_components=512)\n",
    "pca_vector_dep = pca.fit_transform(X_dep)\n",
    "pca_vector_wor = pca.fit_transform(X_wor)\n",
    "\n",
    "response_space_dep = pd.DataFrame(data = pca_vector_dep)\n",
    "response_space_wor = pd.DataFrame(data = pca_vector_wor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.282794</td>\n",
       "      <td>-0.524196</td>\n",
       "      <td>-1.027801</td>\n",
       "      <td>-0.641494</td>\n",
       "      <td>-0.910719</td>\n",
       "      <td>0.250604</td>\n",
       "      <td>-0.360248</td>\n",
       "      <td>-1.856100</td>\n",
       "      <td>0.603526</td>\n",
       "      <td>0.031079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>-0.590871</td>\n",
       "      <td>0.140121</td>\n",
       "      <td>0.038419</td>\n",
       "      <td>0.187508</td>\n",
       "      <td>-0.295742</td>\n",
       "      <td>-0.040504</td>\n",
       "      <td>-0.105643</td>\n",
       "      <td>0.151323</td>\n",
       "      <td>-0.328827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.490762</td>\n",
       "      <td>-0.513754</td>\n",
       "      <td>-0.589719</td>\n",
       "      <td>-0.764626</td>\n",
       "      <td>-0.829384</td>\n",
       "      <td>-0.013092</td>\n",
       "      <td>-0.178670</td>\n",
       "      <td>-0.772768</td>\n",
       "      <td>0.515342</td>\n",
       "      <td>-0.665212</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058596</td>\n",
       "      <td>-0.000172</td>\n",
       "      <td>0.417340</td>\n",
       "      <td>-0.474495</td>\n",
       "      <td>0.288218</td>\n",
       "      <td>-0.057047</td>\n",
       "      <td>0.123040</td>\n",
       "      <td>-0.499483</td>\n",
       "      <td>0.233025</td>\n",
       "      <td>0.293262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.407720</td>\n",
       "      <td>-0.359152</td>\n",
       "      <td>-0.565727</td>\n",
       "      <td>-0.510021</td>\n",
       "      <td>-0.573567</td>\n",
       "      <td>-0.330673</td>\n",
       "      <td>-0.049134</td>\n",
       "      <td>-1.812871</td>\n",
       "      <td>-0.152629</td>\n",
       "      <td>-0.314469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.222353</td>\n",
       "      <td>-0.292018</td>\n",
       "      <td>-0.113159</td>\n",
       "      <td>0.249132</td>\n",
       "      <td>0.044381</td>\n",
       "      <td>0.059403</td>\n",
       "      <td>0.215932</td>\n",
       "      <td>-0.558951</td>\n",
       "      <td>-0.031220</td>\n",
       "      <td>0.012624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.408584</td>\n",
       "      <td>-0.495786</td>\n",
       "      <td>-0.432052</td>\n",
       "      <td>-0.398641</td>\n",
       "      <td>-0.200414</td>\n",
       "      <td>0.965685</td>\n",
       "      <td>-0.364464</td>\n",
       "      <td>-2.239018</td>\n",
       "      <td>0.119474</td>\n",
       "      <td>-0.321005</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097304</td>\n",
       "      <td>-0.038147</td>\n",
       "      <td>0.124730</td>\n",
       "      <td>-0.110798</td>\n",
       "      <td>0.041609</td>\n",
       "      <td>0.099065</td>\n",
       "      <td>0.032272</td>\n",
       "      <td>0.095782</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.139240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.330622</td>\n",
       "      <td>-17.278840</td>\n",
       "      <td>3.143810</td>\n",
       "      <td>8.079438</td>\n",
       "      <td>24.829126</td>\n",
       "      <td>-3.035996</td>\n",
       "      <td>1.942622</td>\n",
       "      <td>1.719282</td>\n",
       "      <td>0.200212</td>\n",
       "      <td>-0.086043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035102</td>\n",
       "      <td>-0.123306</td>\n",
       "      <td>0.118074</td>\n",
       "      <td>-0.133421</td>\n",
       "      <td>0.202534</td>\n",
       "      <td>0.332230</td>\n",
       "      <td>-0.041061</td>\n",
       "      <td>-0.123947</td>\n",
       "      <td>0.016772</td>\n",
       "      <td>-0.120972</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1         2         3          4         5         6    \\\n",
       "0   -1.282794  -0.524196 -1.027801 -0.641494  -0.910719  0.250604 -0.360248   \n",
       "1   -1.490762  -0.513754 -0.589719 -0.764626  -0.829384 -0.013092 -0.178670   \n",
       "2   -1.407720  -0.359152 -0.565727 -0.510021  -0.573567 -0.330673 -0.049134   \n",
       "3   -1.408584  -0.495786 -0.432052 -0.398641  -0.200414  0.965685 -0.364464   \n",
       "4  198.330622 -17.278840  3.143810  8.079438  24.829126 -3.035996  1.942622   \n",
       "\n",
       "        7         8         9    ...       502       503       504       505  \\\n",
       "0 -1.856100  0.603526  0.031079  ...  0.142960 -0.590871  0.140121  0.038419   \n",
       "1 -0.772768  0.515342 -0.665212  ...  0.058596 -0.000172  0.417340 -0.474495   \n",
       "2 -1.812871 -0.152629 -0.314469  ... -0.222353 -0.292018 -0.113159  0.249132   \n",
       "3 -2.239018  0.119474 -0.321005  ... -0.097304 -0.038147  0.124730 -0.110798   \n",
       "4  1.719282  0.200212 -0.086043  ... -0.035102 -0.123306  0.118074 -0.133421   \n",
       "\n",
       "        506       507       508       509       510       511  \n",
       "0  0.187508 -0.295742 -0.040504 -0.105643  0.151323 -0.328827  \n",
       "1  0.288218 -0.057047  0.123040 -0.499483  0.233025  0.293262  \n",
       "2  0.044381  0.059403  0.215932 -0.558951 -0.031220  0.012624  \n",
       "3  0.041609  0.099065  0.032272  0.095782  0.003446  0.139240  \n",
       "4  0.202534  0.332230 -0.041061 -0.123947  0.016772 -0.120972  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_space_dep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important variables \n",
    "\n",
    "Deptext = Depression text-response <br> \n",
    "Wortext = Worry text-response\n",
    "\n",
    "dep_all_phraces = Depression all phraces responses <br> \n",
    "wor_all_phraces = Worry all phraces responses\n",
    "\n",
    "dep_all_word = Depression all descriptive word responses <br>\n",
    "wor_all_words = Worry all descriptive word responses\n",
    "\n",
    "dep_all_selected1 = All selected depression word responses <br>\n",
    "wor_all_selected1 = All selected worry word responses\n",
    "\n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "CESDtot = Center for Epidemiological Studies Depression (CESD) <br>\n",
    "PHQtot = PHQ-9 = Patient Helath Questionnaire = a depression scale\n",
    "\n",
    "GADtot = GAD-7 = Generalized anxiety disorder scale <br>\n",
    "PSWQtot = Penn State Worry Questionniare \n",
    "\n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "miniGAD_diagnose = Self-reported MINI (structured interview) GAD diangose <br>\n",
    "minidep_diagnose = Self-reported MINI (structured interview) MDD (depression) diangose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Semantic Representations in Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The dependent variable for worry and depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Semantic-numeric correlations. \n",
    "Analyzing the relationship between semantic responses and a numerical variable\n",
    "\"\"\"\n",
    "\n",
    "#The numerical rating scales for depression and worry\n",
    "dep_scale = responses[['PHQtot']]\n",
    "wor_scale = responses[['GADtot']]\n",
    "\n",
    "#Checking for NaN values\n",
    "dep_scale.isnull().values.any() #true\n",
    "wor_scale.isnull().values.any() #true\n",
    "\n",
    "def replace_nan(y_array):\n",
    "    #Replaceing NaN values with mean value of column - perhaps we should do this differently\n",
    "    col_mean = np.nanmean(y_array, axis=0)\n",
    "    col_mean = np.around(col_mean, decimals=0, out=None) #rounding \n",
    "    #Find indices that you need to replace\n",
    "    inds = np.where(np.isnan(y_array))\n",
    "    #Place column means in the indices. Align the array using take\n",
    "    y_array[inds] = np.take(col_mean, inds[1])\n",
    "    \n",
    "    return y_array\n",
    "\n",
    "#Create y - variables\n",
    "y_wor = wor_scale.values\n",
    "y_dep = dep_scale.values\n",
    "\n",
    "#Replace NaN Values for the numerical scales\n",
    "y_wor = replace_nan(y_wor).flatten()\n",
    "y_dep = replace_nan(y_dep).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import packages needed for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import median_absolute_error, mean_absolute_error, mean_squared_error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis using plain linear regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Predicting the corresponding numeric rating scales on the basis of these representations by means \n",
    "of multiple linear regression analyses \"\"\"\n",
    "\n",
    "#x_dep = df_dep_concat #To use full concatinated vectors with 2048 dimensions (before PCA)\n",
    "x_dep = response_space_dep #To use vectors with reduced dimensions (after PCA)\n",
    "\n",
    "#Splitting data into training and testing dataset for depression data\n",
    "X_train_dep, X_test_dep, y_train_dep, y_test_dep = train_test_split(x_dep, y_dep, test_size=0.2, random_state=0)\n",
    "\n",
    "regr_dep = LinearRegression().fit(X_train_dep, y_train_dep)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred_dep = regr_dep.predict(X_test_dep) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO -  add table so we can compare the scores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 score for training data:  \", regr_dep.score(X_train_dep, y_train_dep)) #R2 score for training data is 0.8\n",
    "print(\"R2 score for testing data:  \", regr_dep.score(X_test_dep, y_test_dep)) #R2 score for test data is -223.13 \n",
    "\n",
    "print(\"Root Mean Squared Error (RMSE):  \", np.sqrt(metrics.mean_squared_error(y_test_dep, y_pred_dep)))\n",
    "print(\"Intercept:  \", regr_dep.intercept_)\n",
    "#print(regr_dep.coef_)\n",
    "\n",
    "# ...... Probably overfitted (judging by the R2 values) !!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiple linear regression analysis for anxiety data \n",
    "\n",
    "#x_wor = df_wor_concat #To use full concatinated vectors with 2048 dimensions (before PCA)\n",
    "x_wor = response_space_wor #To use vectors with reduced dimensions (after PCA)\n",
    "\n",
    "#Splitting data into training and testing dataset for depression data\n",
    "X_train_wor, X_test_wor, y_train_wor, y_test_wor = train_test_split(x_wor, y_wor, test_size=0.2, random_state=0)\n",
    "\n",
    "regr_wor = LinearRegression()\n",
    "regr_wor.fit(X_train_wor, y_train_wor)\n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred_wor = regr_wor.predict(X_test_wor) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"R2 score for worry training data:  \", regr_wor.score(X_train_wor, y_train_wor)) #R2 score for training data is 0.67\n",
    "print(\"R2 score for worry testing data:  \", regr_wor.score(X_test_wor, y_test_wor)) #R2 score for test data is -10\n",
    "print(\"Root Mean Squared Error (RMSE):  \", np.sqrt(mean_squared_error(y_test_wor, y_pred_wor)))\n",
    "print(\"Intercept:  \", regr_wor.intercept_)\n",
    "\n",
    "print(\"Median absolute error for test data: \", median_absolute_error(y_pred_wor, y_test_wor))\n",
    "print(\"Median absolute error for training data: \", median_absolute_error(regr_wor.predict(X_train_wor), y_train_wor))\n",
    "\n",
    "#print(regr.coef_)\n",
    "\n",
    "# ...... Probably overfitted (judging by the R2 values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining optimal number of dimensions\n",
    "### Using the method described in the article combined with plain linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"In practice, this was simply achieved by adding 1, \n",
    "then multiplying by 1.3 and finally rounding to the nearest integer \n",
    "(e.g., 1, 3, 5, 8, where the next number of dimen- sions to be tested are the first 12; \n",
    "in other words ([8 􏰃 1] 􏰍 1.3).\n",
    "In previous research, we have found this sequence to be valid and computationally efficient\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing values\n",
    "n, min_err = 1, np.inf\n",
    "\n",
    "# df_wor_concat => To use full concatinated vectors with 2048 dimensions (before PCA)\n",
    "# response_space_wor => To use vectors with reduced dimensions (after PCA)\n",
    "\n",
    "new_x=df_wor_concat\n",
    "\n",
    "while n < len(df_wor_concat.columns):\n",
    "    \n",
    "    #split data into train and test data\n",
    "    X_train_wor, X_test_wor, y_train_wor, y_test_wor = train_test_split(new_x, y_wor, test_size=0.2, random_state=0)\n",
    "    y_train_wor = y_train_wor.flatten() \n",
    "    y_test_wor = y_test_wor.flatten()\n",
    "    \n",
    "    regr_wor = LinearRegression()\n",
    "    \n",
    "    #fit data\n",
    "    regr_wor.fit(X_train_wor, y_train_wor)\n",
    "    \n",
    "    #make prediction \n",
    "    y_pred_wor = regr_wor.predict(X_test_wor) \n",
    "    \n",
    "    #test prediction with mean squared error \n",
    "    err = mean_squared_error(y_test_wor, y_pred_wor)\n",
    "    \n",
    "    #compare err with current min err to then later choose the nbr of dimensions that give minimum mean squared error\n",
    "    if err < min_err:\n",
    "        min_err = err\n",
    "        dimensions=n\n",
    "        r2 = regr_wor.score(X_test_wor, y_test_wor)\n",
    "    \n",
    "    n=round((n+1)*1.3)\n",
    "    new_x=df_wor_concat.iloc[:,:n]  \n",
    "\n",
    "print('Nbr of dimensions to use : ', dimensions) #According to this we should use 56 dimensions in the next steps?\n",
    "print(min_err)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Using the depression data to test how many dimensions to keep\"\n",
    "\n",
    "y_dim = y_dep\n",
    "dimension, min_error = 0, np.inf\n",
    "i = 1\n",
    "\n",
    "# df_wor_concat => To use full concatinated vectors with 2048 dimensions (before PCA)\n",
    "# response_space_wor => To use vectors with reduced dimensions (after PCA)\n",
    "\n",
    "while i < len(df_dep_concat.columns):\n",
    "    x_dim = df_dep_concat.iloc[:,:i]\n",
    "    X_train_dim, X_test_dim, y_train_dim, y_test_dim = train_test_split(x_dim, y_dim, test_size=0.2, random_state=0)\n",
    "\n",
    "    regr_dim = LinearRegression()\n",
    "    \n",
    "    regr_dim.fit(X_train_dim, y_train_dim)\n",
    "    y_pred_dim = regr_dim.predict(X_test_dim) \n",
    "    \n",
    "    mse = mean_squared_error(y_test_dim, y_pred_dim)\n",
    "    \n",
    "    if mse < min_error: \n",
    "        min_error = mse\n",
    "        dimension = i\n",
    "        r2 = regr_dim.score(X_test_dim, y_test_dim)\n",
    "    \n",
    "    #print(i, mse)\n",
    "    i = round((i + 1)*1.3)\n",
    "    \n",
    "print('\\nNbr of dimensions to use: ', dimension)\n",
    "print(min_error, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Results examining optimal number of dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Depression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technique | Original dimension | R2 score | MSE | Nbr dimensions\n",
    "----- | --- | --- | --- | --- \n",
    "**(i+1)*1.3** from article w/ **linReg** | PCA red vec: 512 | 0.040 | 51.80 | 17\n",
    "**(i+1)*1.3** from article w/ **linReg** | Full concat: 2048\t | 0.136 | 46.62 | 56\n",
    "**(i+1)*1.3** from article w/ **leave 10% CV** | Full concat: 2048 | -0.025 | 6.828 | 74\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anxiety"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Technique | Original dimension | R2 score | MSE | Nbr dimensions\n",
    "----- | --- | --- | --- | --- \n",
    "**(i+1)*1.3** from article w/ **linReg** | PCA red vec: 512 | 0.131 | 31.42 | 56\n",
    "**(i+1)*1.3** from article w/ **linReg** | Full concat: 2048 | 0.131 | 31.42 | 98\n",
    "**(i+1)*1.3** from article w/ **leave 10% CV** | Full concat: 2048 | -0.112 | 7.169 | 56\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining optimal number of dimensions using method described in article combined with leave 10% cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Depression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave 10% out cross validation while testing the number of dimensions that will give the best over all score. \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "nbr_folds = round(len(responses)*0.1)\n",
    "cv = KFold(n_splits=nbr_folds, random_state=1, shuffle=True)\n",
    "\n",
    "reg = LinearRegression()\n",
    "dimension, min_error = 0, -np.inf\n",
    "i = 1\n",
    "\n",
    "#df_dep_concat      => To use full concatinated vectors with 2048 dimensions (before PCA)\n",
    "#response_space_dep => To use vectors with reduced dimensions (after PCA)\n",
    "\n",
    "while i < len(df_dep_concat.columns):\n",
    "    x_dep_cv = df_dep_concat.iloc[:,:i]\n",
    "    \n",
    "    #Options for scoring: 'r2', 'neg_root_mean_squared_error' \n",
    "    scores = cross_val_score(reg, x_dep_cv, y_dep, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    if scores.mean() > min_error:\n",
    "        min_error = scores.mean()\n",
    "        dimension = i\n",
    "        \n",
    "    i = round((i + 1)*1.3)\n",
    "    \n",
    "print(\"Best score: {} with dimension: {}\".format(min_error, dimension)) #Using dep data => 74 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anxiety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave 10% out cross validation while testing the number of dimensions that will give the best over all score. \n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "nbr_folds = round(len(responses)*0.1)\n",
    "cv = KFold(n_splits=nbr_folds, random_state=1, shuffle=True)\n",
    "\n",
    "reg = LinearRegression()\n",
    "dimension, min_error = 0, -np.inf\n",
    "i = 1\n",
    "\n",
    "#df_wor_concat      => To use full concatinated vectors with 2048 dimensions (before PCA)\n",
    "#response_space_wor => To use vectors with reduced dimensions (after PCA)\n",
    "\n",
    "while i < len(df_wor_concat.columns):\n",
    "    x_wor_cv = df_wor_concat.iloc[:,:i]\n",
    "    \n",
    "    #Options for scoring: 'r2', 'neg_root_mean_squared_error' \n",
    "    scores = cross_val_score(reg, x_wor_cv, y_dep, scoring='r2', cv=cv, n_jobs=-1)\n",
    "    \n",
    "    if scores.mean() > min_error:\n",
    "        min_error = scores.mean()\n",
    "        dimension = i\n",
    "        \n",
    "    i = round((i + 1)*1.3)\n",
    "    \n",
    "print(\"Best score: {} with dimension: {}\".format(min_error, dimension)) #Using wor data => 56 dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave 10% out cross validation on PCA reduced vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leave 10% out cross validation using PCA reduced vectors\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "nbr_folds = round(len(responses)*0.1)\n",
    "cv = KFold(n_splits=nbr_folds, random_state=1, shuffle=True)\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "#df_dep_concat      => To use full concatinated vectors with 2048 dimensions (before PCA)\n",
    "x_dep_cv = response_space_dep #=> To use vectors with reduced dimensions (after PCA)\n",
    "\n",
    "#Options for scoring: 'r2', 'neg_root_mean_squared_error' \n",
    "scores = cross_val_score(reg, x_dep_cv, y_dep, scoring='neg_root_mean_squared_error', cv=cv, n_jobs=-1)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave one out cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOOCV \n",
    "#new=x_wor.copy()\n",
    "#new.columns = new.columns.str.replace('X', '')\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "cv = LeaveOneOut()\n",
    "\n",
    "regr = LinearRegression()\n",
    "scores = cross_val_score(regr, X_wor, y_wor, scoring='neg_mean_absolute_error', cv=cv) #, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=np.absolute(scores)\n",
    "print(' %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LeavePOut(p=1)\n",
    "from sklearn.model_selection import LeavePOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StratifiedKFold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ShuffleSplit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
