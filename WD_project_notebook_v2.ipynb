{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitdate</th>\n",
       "      <th>lastpage</th>\n",
       "      <th>startlanguage</th>\n",
       "      <th>seed</th>\n",
       "      <th>startdate</th>\n",
       "      <th>datestamp</th>\n",
       "      <th>sequence1</th>\n",
       "      <th>seqOne</th>\n",
       "      <th>Dep5words[Word1]</th>\n",
       "      <th>...</th>\n",
       "      <th>wor_all_selected</th>\n",
       "      <th>wor_all_selected1</th>\n",
       "      <th>minidep_scale</th>\n",
       "      <th>minidep_diagnose</th>\n",
       "      <th>depression_episodes</th>\n",
       "      <th>miniGAD_scale</th>\n",
       "      <th>miniGAD_symptoms_scale</th>\n",
       "      <th>miniGAD_diagnose</th>\n",
       "      <th>minidiagnose_category</th>\n",
       "      <th>minidiagnose_category_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>434.0</td>\n",
       "      <td>2020-08-07 11:46:22</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>6.593644e+08</td>\n",
       "      <td>2020-08-07 11:38:22</td>\n",
       "      <td>2020-08-07 11:46:22</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>motivated</td>\n",
       "      <td>...</td>\n",
       "      <td>NA NA happy NA NA NA NA NA NA NA NA NA NA care...</td>\n",
       "      <td>happy           carefree     satisfied      ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>184.0</td>\n",
       "      <td>2020-08-07 11:58:36</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>2.803892e+08</td>\n",
       "      <td>2020-08-07 11:34:31</td>\n",
       "      <td>2020-08-07 11:58:36</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>connected</td>\n",
       "      <td>...</td>\n",
       "      <td>anxious NA NA NA NA NA NA NA NA NA NA tense NA...</td>\n",
       "      <td>anxious           tense    fearful  sad     fe...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>330.0</td>\n",
       "      <td>2020-08-07 11:51:54</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>6.770686e+07</td>\n",
       "      <td>2020-08-07 11:36:32</td>\n",
       "      <td>2020-08-07 11:51:54</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>...</td>\n",
       "      <td>anxious NA NA NA NA NA worried NA NA NA NA NA ...</td>\n",
       "      <td>anxious      worried      scared     sad   mon...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>630.0</td>\n",
       "      <td>2020-08-07 13:22:42</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.176643e+09</td>\n",
       "      <td>2020-08-07 12:55:26</td>\n",
       "      <td>2020-08-07 13:22:42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>minor</td>\n",
       "      <td>...</td>\n",
       "      <td>anxious NA NA NA NA concerned NA NA NA NA NA t...</td>\n",
       "      <td>anxious     concerned      tense scared       ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NoDi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400.0</td>\n",
       "      <td>2020-08-07 12:04:52</td>\n",
       "      <td>15.0</td>\n",
       "      <td>en</td>\n",
       "      <td>1.012492e+09</td>\n",
       "      <td>2020-08-07 11:37:19</td>\n",
       "      <td>2020-08-07 12:04:52</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>family</td>\n",
       "      <td>...</td>\n",
       "      <td>NA NA NA NA NA concerned NA NA NA NA NA tense ...</td>\n",
       "      <td>concerned      tense      sad      tired ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>GAD</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 407 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id           submitdate  lastpage startlanguage          seed  \\\n",
       "0  434.0  2020-08-07 11:46:22      15.0            en  6.593644e+08   \n",
       "1  184.0  2020-08-07 11:58:36      15.0            en  2.803892e+08   \n",
       "2  330.0  2020-08-07 11:51:54      15.0            en  6.770686e+07   \n",
       "3  630.0  2020-08-07 13:22:42      15.0            en  1.176643e+09   \n",
       "4  400.0  2020-08-07 12:04:52      15.0            en  1.012492e+09   \n",
       "\n",
       "             startdate            datestamp  sequence1  seqOne  \\\n",
       "0  2020-08-07 11:38:22  2020-08-07 11:46:22        2.0     1.0   \n",
       "1  2020-08-07 11:34:31  2020-08-07 11:58:36        2.0     1.0   \n",
       "2  2020-08-07 11:36:32  2020-08-07 11:51:54        1.0     1.0   \n",
       "3  2020-08-07 12:55:26  2020-08-07 13:22:42        3.0     1.0   \n",
       "4  2020-08-07 11:37:19  2020-08-07 12:04:52        1.0     1.0   \n",
       "\n",
       "  Dep5words[Word1]  ...                                   wor_all_selected  \\\n",
       "0        motivated  ...  NA NA happy NA NA NA NA NA NA NA NA NA NA care...   \n",
       "1        connected  ...  anxious NA NA NA NA NA NA NA NA NA NA tense NA...   \n",
       "2              Yes  ...  anxious NA NA NA NA NA worried NA NA NA NA NA ...   \n",
       "3            minor  ...  anxious NA NA NA NA concerned NA NA NA NA NA t...   \n",
       "4           family  ...  NA NA NA NA NA concerned NA NA NA NA NA tense ...   \n",
       "\n",
       "                                   wor_all_selected1 minidep_scale  \\\n",
       "0    happy           carefree     satisfied      ...           0.0   \n",
       "1  anxious           tense    fearful  sad     fe...           3.0   \n",
       "2  anxious      worried      scared     sad   mon...           7.0   \n",
       "3  anxious     concerned      tense scared       ...           3.0   \n",
       "4       concerned      tense      sad      tired ...           4.0   \n",
       "\n",
       "  minidep_diagnose depression_episodes miniGAD_scale miniGAD_symptoms_scale  \\\n",
       "0                0                   0             0                      0   \n",
       "1                0                   0             8                      5   \n",
       "2                0                   5             9                      5   \n",
       "3                0                   5             8                      5   \n",
       "4                0                   2             7                      4   \n",
       "\n",
       "  miniGAD_diagnose minidiagnose_category  minidiagnose_category_number  \n",
       "0                0                  NoDi                             0  \n",
       "1                0                  NoDi                             0  \n",
       "2                0                  NoDi                             0  \n",
       "3                0                  NoDi                             0  \n",
       "4                1                   GAD                             2  \n",
       "\n",
       "[5 rows x 407 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "responses = pd.read_csv('../data/response_format_cleaned_ds1.csv', sep=';', header=0)\n",
    "responses.drop(responses.columns[[0]], axis=1, inplace=True)\n",
    "responses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Only for understanding data and visualize a response example.\n",
    "Prints column name and response of patient at row 0.\n",
    "\"\"\"\n",
    "for res, col in zip(responses.iloc[0], responses.columns):\n",
    "    print(\"{} -> {}\".format(col, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using 5-gram contexts from the database, a co-occurrence (word by word) matrix was set up, \n",
    "where the rows contained the 120,000 most common words in the n-gram database and the columns \n",
    "consisted of the 10,000 most common words in the n-gram database.\n",
    "\n",
    "The variable 'space' is a matrix of the semantic space with dimentions reduced to 512.\n",
    "\"\"\"\n",
    "space = pd.read_csv('../data/spaceEnglish1.csv', encoding= 'unicode_escape')\n",
    "space.set_index('words', inplace=True)\n",
    "space.drop(space.columns[[0]], axis=1, inplace=True)\n",
    "space.dropna(inplace=True)\n",
    "space = space[~space.index.duplicated(keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X503</th>\n",
       "      <th>X504</th>\n",
       "      <th>X505</th>\n",
       "      <th>X506</th>\n",
       "      <th>X507</th>\n",
       "      <th>X508</th>\n",
       "      <th>X509</th>\n",
       "      <th>X510</th>\n",
       "      <th>X511</th>\n",
       "      <th>X512</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>was</th>\n",
       "      <td>-0.234071</td>\n",
       "      <td>-0.278211</td>\n",
       "      <td>-0.100658</td>\n",
       "      <td>-0.269570</td>\n",
       "      <td>-0.115498</td>\n",
       "      <td>-0.000038</td>\n",
       "      <td>-0.036835</td>\n",
       "      <td>0.024037</td>\n",
       "      <td>-0.003974</td>\n",
       "      <td>0.006582</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011414</td>\n",
       "      <td>0.018075</td>\n",
       "      <td>-0.020312</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>0.012867</td>\n",
       "      <td>0.021265</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.024858</td>\n",
       "      <td>-0.020382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not</th>\n",
       "      <td>-0.283230</td>\n",
       "      <td>-0.338776</td>\n",
       "      <td>-0.141085</td>\n",
       "      <td>-0.243715</td>\n",
       "      <td>-0.236692</td>\n",
       "      <td>-0.033354</td>\n",
       "      <td>-0.099906</td>\n",
       "      <td>0.053253</td>\n",
       "      <td>-0.025582</td>\n",
       "      <td>-0.040372</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.028472</td>\n",
       "      <td>0.048824</td>\n",
       "      <td>-0.025452</td>\n",
       "      <td>0.007828</td>\n",
       "      <td>0.027658</td>\n",
       "      <td>-0.022135</td>\n",
       "      <td>0.023037</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>-0.001482</td>\n",
       "      <td>-0.024063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>by</th>\n",
       "      <td>-0.251058</td>\n",
       "      <td>-0.327183</td>\n",
       "      <td>-0.203889</td>\n",
       "      <td>-0.283337</td>\n",
       "      <td>-0.124522</td>\n",
       "      <td>-0.006537</td>\n",
       "      <td>0.015371</td>\n",
       "      <td>0.131667</td>\n",
       "      <td>-0.130597</td>\n",
       "      <td>0.055605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001550</td>\n",
       "      <td>0.027915</td>\n",
       "      <td>-0.012646</td>\n",
       "      <td>-0.005019</td>\n",
       "      <td>0.075544</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>-0.022636</td>\n",
       "      <td>0.010127</td>\n",
       "      <td>-0.027951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>that</th>\n",
       "      <td>-0.281888</td>\n",
       "      <td>-0.346746</td>\n",
       "      <td>-0.171006</td>\n",
       "      <td>-0.266698</td>\n",
       "      <td>-0.208917</td>\n",
       "      <td>-0.019832</td>\n",
       "      <td>-0.035404</td>\n",
       "      <td>0.044301</td>\n",
       "      <td>-0.076601</td>\n",
       "      <td>0.021328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019319</td>\n",
       "      <td>0.042742</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.019198</td>\n",
       "      <td>0.022598</td>\n",
       "      <td>0.034352</td>\n",
       "      <td>0.033282</td>\n",
       "      <td>-0.006843</td>\n",
       "      <td>0.027052</td>\n",
       "      <td>-0.013623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>-0.256530</td>\n",
       "      <td>-0.335434</td>\n",
       "      <td>-0.229791</td>\n",
       "      <td>-0.256070</td>\n",
       "      <td>-0.120020</td>\n",
       "      <td>0.017080</td>\n",
       "      <td>0.078004</td>\n",
       "      <td>0.112134</td>\n",
       "      <td>-0.073805</td>\n",
       "      <td>0.098183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>-0.022383</td>\n",
       "      <td>-0.042172</td>\n",
       "      <td>-0.003430</td>\n",
       "      <td>-0.013435</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>-0.022769</td>\n",
       "      <td>0.024873</td>\n",
       "      <td>0.010061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             X1        X2        X3        X4        X5        X6        X7  \\\n",
       "words                                                                         \n",
       "was   -0.234071 -0.278211 -0.100658 -0.269570 -0.115498 -0.000038 -0.036835   \n",
       "not   -0.283230 -0.338776 -0.141085 -0.243715 -0.236692 -0.033354 -0.099906   \n",
       "by    -0.251058 -0.327183 -0.203889 -0.283337 -0.124522 -0.006537  0.015371   \n",
       "that  -0.281888 -0.346746 -0.171006 -0.266698 -0.208917 -0.019832 -0.035404   \n",
       "of    -0.256530 -0.335434 -0.229791 -0.256070 -0.120020  0.017080  0.078004   \n",
       "\n",
       "             X8        X9       X10  ...      X503      X504      X505  \\\n",
       "words                                ...                                 \n",
       "was    0.024037 -0.003974  0.006582  ... -0.011414  0.018075 -0.020312   \n",
       "not    0.053253 -0.025582 -0.040372  ... -0.028472  0.048824 -0.025452   \n",
       "by     0.131667 -0.130597  0.055605  ... -0.001550  0.027915 -0.012646   \n",
       "that   0.044301 -0.076601  0.021328  ...  0.019319  0.042742  0.001747   \n",
       "of     0.112134 -0.073805  0.098183  ...  0.012012  0.005470 -0.022383   \n",
       "\n",
       "           X506      X507      X508      X509      X510      X511      X512  \n",
       "words                                                                        \n",
       "was    0.001287  0.024483  0.012867  0.021265  0.016368  0.024858 -0.020382  \n",
       "not    0.007828  0.027658 -0.022135  0.023037  0.005371 -0.001482 -0.024063  \n",
       "by    -0.005019  0.075544  0.014663  0.013489 -0.022636  0.010127 -0.027951  \n",
       "that   0.019198  0.022598  0.034352  0.033282 -0.006843  0.027052 -0.013623  \n",
       "of    -0.042172 -0.003430 -0.013435  0.003697 -0.022769  0.024873  0.010061  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Cleans the string from punctuations and removes all words which are not represented in the semantic space. \n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import math\n",
    "\n",
    "words_in_space = set(space.index.values)\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        try:\n",
    "            text = text.lower()\n",
    "            text = re.sub(r'[^\\w\\s]', '', text)\n",
    "            text = list(set(text.split()))\n",
    "            cleaned_words = [w for w in text if w in words_in_space] # TODO: Hantera ord som inte finns i spacet. Nu ignoreras dem.\n",
    "            return cleaned_words\n",
    "        except Exception as e: \n",
    "            print(e)\n",
    "    elif math.isnan(text):\n",
    "        return []\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Controlling for artifacts relating to frequently occurring words.\n",
    "\n",
    "1) Calculate, from Google N-gram, a frequency weighted average of all semantic representations in the space.\n",
    "   (So that the weighting is proportional to how frequently the words occur in Google N-gram.)\n",
    "2) Subtract this mean prior to aggregating each word, and then add to the final value.\n",
    "\"\"\"\n",
    "\n",
    "space_mean = pd.Series.to_numpy(space.mean())\n",
    "\n",
    "def aggregating_words(responses):\n",
    "    res_arr = np.zeros(512)\n",
    "    \n",
    "    for word in responses:\n",
    "        word_arr = pd.Series.to_numpy(space.loc[word])\n",
    "        res_arr = res_arr + (word_arr - space_mean)\n",
    "    \n",
    "    res_arr += space_mean    \n",
    "    res_arr = res_arr / res_arr.sum() # Normalizing aggregated vector\n",
    "    return res_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_cell(text):\n",
    "    words_in_cell = pd.Series.apply(text, clean_text)\n",
    "    cell_vectors = pd.Series.apply(words_in_cell, aggregating_words)\n",
    "    return cell_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep_columns = ['Deptext', 'dep_all_phraces', 'dep_all_words', 'dep_all_selected1']\n",
    "df_dep_responses = responses[dep_columns]\n",
    "\n",
    "df_dep_aggregated = df_dep_responses.apply(aggregate_cell, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "wor_columns = ['Wortext', 'wor_all_phraces', 'wor_all_words', 'wor_all_selected1']\n",
    "df_wor_responses = responses[wor_columns]\n",
    "\n",
    "df_wor_aggregated = df_wor_responses.apply(aggregate_cell, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Deptext</th>\n",
       "      <th>dep_all_phraces</th>\n",
       "      <th>dep_all_words</th>\n",
       "      <th>dep_all_selected1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.14620488346512742, 0.20439917711775293, 0.0...</td>\n",
       "      <td>[-0.7590918166513144, -0.7996448245182226, 0.6...</td>\n",
       "      <td>[-0.12735496139054883, -0.08134255488745973, 0...</td>\n",
       "      <td>[-0.10631367041145828, -0.0761176566484352, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.1687325994480793, 0.22817746128469954, -0.0...</td>\n",
       "      <td>[0.3150959567419946, 0.4207709520192084, 0.015...</td>\n",
       "      <td>[1.481708549565079, 1.68527947556706, -1.02609...</td>\n",
       "      <td>[-0.44645774520185727, -0.3896723426287448, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.15851603167923164, 0.217751607989601, 0.031...</td>\n",
       "      <td>[0.09205027035822108, 0.12041302636339311, 0.0...</td>\n",
       "      <td>[0.12709153308204266, 0.14295118020024067, -0....</td>\n",
       "      <td>[-0.07663349903279251, -0.0006333442681840852,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.15762474074250946, 0.21672014178412558, 0.0...</td>\n",
       "      <td>[0.2704033968315661, 0.35429957613545476, -0.0...</td>\n",
       "      <td>[0.025633109762595925, 0.008765453890638987, -...</td>\n",
       "      <td>[-0.07360932328901602, -0.03903701225966791, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.1919698469397765, 0.26635971533780395, 0.01...</td>\n",
       "      <td>[0.39916260826011757, 0.4636167724424406, -0.1...</td>\n",
       "      <td>[0.10400074631268061, 0.11652565658484361, -0....</td>\n",
       "      <td>[53.49798528434978, 36.20381427223155, -104.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.16020033435596978, 0.22476856909904844, 0.0...</td>\n",
       "      <td>[0.4163829239997853, 0.5368902458559512, -0.04...</td>\n",
       "      <td>[-0.026319931002123525, -0.008734687972281292,...</td>\n",
       "      <td>[-0.09433512754889445, -0.04938581939782907, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.24168212896922375, 0.33902324777852244, 0.0...</td>\n",
       "      <td>[0.13731923979741933, 0.17728122055888806, 0.0...</td>\n",
       "      <td>[-0.21575673903918435, -0.17254878886225866, 0...</td>\n",
       "      <td>[-0.07639443687669706, -0.06505044300142827, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.19748763475130368, 0.2696508766614911, 0.02...</td>\n",
       "      <td>[0.13360152439614426, 0.1815627422093893, 0.02...</td>\n",
       "      <td>[-0.19561638585825628, -0.14930168873878924, 0...</td>\n",
       "      <td>[0.28285568876115946, 0.2521117267827112, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.20163162925816497, 0.2766626351045351, 0.00...</td>\n",
       "      <td>[-0.4567649142131939, -0.17522813017334934, 0....</td>\n",
       "      <td>[-0.1390705297657966, -0.08380077038092038, 0....</td>\n",
       "      <td>[-2.0148557305068096, -1.7268435631282695, 3.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.16036779308098764, 0.22456358894876233, 0.0...</td>\n",
       "      <td>[0.23138802445768988, 0.31897402139246045, 0.0...</td>\n",
       "      <td>[-0.3710269064624872, -0.38723656128234063, 0....</td>\n",
       "      <td>[-0.23176359942669628, -0.20155104925319123, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Deptext  \\\n",
       "0  [0.14620488346512742, 0.20439917711775293, 0.0...   \n",
       "1  [0.1687325994480793, 0.22817746128469954, -0.0...   \n",
       "2  [0.15851603167923164, 0.217751607989601, 0.031...   \n",
       "3  [0.15762474074250946, 0.21672014178412558, 0.0...   \n",
       "4  [0.1919698469397765, 0.26635971533780395, 0.01...   \n",
       "5  [0.16020033435596978, 0.22476856909904844, 0.0...   \n",
       "6  [0.24168212896922375, 0.33902324777852244, 0.0...   \n",
       "7  [0.19748763475130368, 0.2696508766614911, 0.02...   \n",
       "8  [0.20163162925816497, 0.2766626351045351, 0.00...   \n",
       "9  [0.16036779308098764, 0.22456358894876233, 0.0...   \n",
       "\n",
       "                                     dep_all_phraces  \\\n",
       "0  [-0.7590918166513144, -0.7996448245182226, 0.6...   \n",
       "1  [0.3150959567419946, 0.4207709520192084, 0.015...   \n",
       "2  [0.09205027035822108, 0.12041302636339311, 0.0...   \n",
       "3  [0.2704033968315661, 0.35429957613545476, -0.0...   \n",
       "4  [0.39916260826011757, 0.4636167724424406, -0.1...   \n",
       "5  [0.4163829239997853, 0.5368902458559512, -0.04...   \n",
       "6  [0.13731923979741933, 0.17728122055888806, 0.0...   \n",
       "7  [0.13360152439614426, 0.1815627422093893, 0.02...   \n",
       "8  [-0.4567649142131939, -0.17522813017334934, 0....   \n",
       "9  [0.23138802445768988, 0.31897402139246045, 0.0...   \n",
       "\n",
       "                                       dep_all_words  \\\n",
       "0  [-0.12735496139054883, -0.08134255488745973, 0...   \n",
       "1  [1.481708549565079, 1.68527947556706, -1.02609...   \n",
       "2  [0.12709153308204266, 0.14295118020024067, -0....   \n",
       "3  [0.025633109762595925, 0.008765453890638987, -...   \n",
       "4  [0.10400074631268061, 0.11652565658484361, -0....   \n",
       "5  [-0.026319931002123525, -0.008734687972281292,...   \n",
       "6  [-0.21575673903918435, -0.17254878886225866, 0...   \n",
       "7  [-0.19561638585825628, -0.14930168873878924, 0...   \n",
       "8  [-0.1390705297657966, -0.08380077038092038, 0....   \n",
       "9  [-0.3710269064624872, -0.38723656128234063, 0....   \n",
       "\n",
       "                                   dep_all_selected1  \n",
       "0  [-0.10631367041145828, -0.0761176566484352, 0....  \n",
       "1  [-0.44645774520185727, -0.3896723426287448, 0....  \n",
       "2  [-0.07663349903279251, -0.0006333442681840852,...  \n",
       "3  [-0.07360932328901602, -0.03903701225966791, 0...  \n",
       "4  [53.49798528434978, 36.20381427223155, -104.12...  \n",
       "5  [-0.09433512754889445, -0.04938581939782907, 0...  \n",
       "6  [-0.07639443687669706, -0.06505044300142827, 0...  \n",
       "7  [0.28285568876115946, 0.2521117267827112, -0.3...  \n",
       "8  [-2.0148557305068096, -1.7268435631282695, 3.1...  \n",
       "9  [-0.23176359942669628, -0.20155104925319123, 0...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dep_aggregated.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wortext</th>\n",
       "      <th>wor_all_phraces</th>\n",
       "      <th>wor_all_words</th>\n",
       "      <th>wor_all_selected1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.148989815726339, 0.20678471111840982, 0.023...</td>\n",
       "      <td>[0.16848163704578223, 0.2110408595467317, 0.00...</td>\n",
       "      <td>[0.08512889256007851, 0.06930940294720918, -0....</td>\n",
       "      <td>[-0.03628907508059879, -0.028415450913131562, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.16658035037273555, 0.22419803669426439, -0....</td>\n",
       "      <td>[2.926113550483038, 3.775815574093923, -0.2913...</td>\n",
       "      <td>[-0.5054823889786448, -0.1719085052464011, 0.2...</td>\n",
       "      <td>[-0.04345398189988287, -0.020184341988825117, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.14912997482144705, 0.2077058877329334, 0.03...</td>\n",
       "      <td>[0.10662762521250932, 0.12498854698322398, -0....</td>\n",
       "      <td>[0.07113400315024145, 0.07405232367513158, -0....</td>\n",
       "      <td>[-0.2445014187941481, -0.12076884155682255, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.14166991480328237, 0.19702991519885324, 0.0...</td>\n",
       "      <td>[-0.20939610364178612, -0.02262574654514594, 0...</td>\n",
       "      <td>[-0.06529720047146928, 0.0462673323090299, 0.2...</td>\n",
       "      <td>[-0.1487217599810065, -0.09152232772736152, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.18670963544273275, 0.25676537028535223, 0.0...</td>\n",
       "      <td>[0.26847344035296594, 0.33163575806082485, 0.0...</td>\n",
       "      <td>[-0.08879341781163708, -0.07424974126664868, 0...</td>\n",
       "      <td>[-0.06327165709289424, -0.04194209704023101, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0.2411979563481076, 0.3323859887436076, 0.034...</td>\n",
       "      <td>[0.46890125346292644, 0.587621833904448, -0.04...</td>\n",
       "      <td>[-0.30424776300405126, -0.04949671606636581, 0...</td>\n",
       "      <td>[-0.04199190272889661, -0.024059956123692574, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[0.24362128776903585, 0.3363286804922321, 0.01...</td>\n",
       "      <td>[0.14751288417729552, 0.19693854765932112, 0.0...</td>\n",
       "      <td>[0.11098324236286285, 0.036409039030220754, -0...</td>\n",
       "      <td>[0.3334432322058594, 0.26953732272642733, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0.16857844964441268, 0.2354066342337168, 0.03...</td>\n",
       "      <td>[0.15824374599203705, 0.20497218134088435, -0....</td>\n",
       "      <td>[-0.2617804024662385, 0.007203681762336978, 0....</td>\n",
       "      <td>[0.06378269752602976, 0.008016117756634652, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[0.18522021167783884, 0.2544669083751666, 0.00...</td>\n",
       "      <td>[0.11635905622328928, 0.018585133221237265, -0...</td>\n",
       "      <td>[0.06984923510555667, 0.0065180639121361, -0.1...</td>\n",
       "      <td>[0.08754686825446154, 0.06462605258728957, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[0.2046066832838274, 0.28211646776321403, 0.02...</td>\n",
       "      <td>[0.1755492642411605, 0.2157095366202667, -0.03...</td>\n",
       "      <td>[-0.10305678157119323, -0.04645025593640229, 0...</td>\n",
       "      <td>[-0.317957439407505, -0.17534088139707735, 0.5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Wortext  \\\n",
       "0  [0.148989815726339, 0.20678471111840982, 0.023...   \n",
       "1  [0.16658035037273555, 0.22419803669426439, -0....   \n",
       "2  [0.14912997482144705, 0.2077058877329334, 0.03...   \n",
       "3  [0.14166991480328237, 0.19702991519885324, 0.0...   \n",
       "4  [0.18670963544273275, 0.25676537028535223, 0.0...   \n",
       "5  [0.2411979563481076, 0.3323859887436076, 0.034...   \n",
       "6  [0.24362128776903585, 0.3363286804922321, 0.01...   \n",
       "7  [0.16857844964441268, 0.2354066342337168, 0.03...   \n",
       "8  [0.18522021167783884, 0.2544669083751666, 0.00...   \n",
       "9  [0.2046066832838274, 0.28211646776321403, 0.02...   \n",
       "\n",
       "                                     wor_all_phraces  \\\n",
       "0  [0.16848163704578223, 0.2110408595467317, 0.00...   \n",
       "1  [2.926113550483038, 3.775815574093923, -0.2913...   \n",
       "2  [0.10662762521250932, 0.12498854698322398, -0....   \n",
       "3  [-0.20939610364178612, -0.02262574654514594, 0...   \n",
       "4  [0.26847344035296594, 0.33163575806082485, 0.0...   \n",
       "5  [0.46890125346292644, 0.587621833904448, -0.04...   \n",
       "6  [0.14751288417729552, 0.19693854765932112, 0.0...   \n",
       "7  [0.15824374599203705, 0.20497218134088435, -0....   \n",
       "8  [0.11635905622328928, 0.018585133221237265, -0...   \n",
       "9  [0.1755492642411605, 0.2157095366202667, -0.03...   \n",
       "\n",
       "                                       wor_all_words  \\\n",
       "0  [0.08512889256007851, 0.06930940294720918, -0....   \n",
       "1  [-0.5054823889786448, -0.1719085052464011, 0.2...   \n",
       "2  [0.07113400315024145, 0.07405232367513158, -0....   \n",
       "3  [-0.06529720047146928, 0.0462673323090299, 0.2...   \n",
       "4  [-0.08879341781163708, -0.07424974126664868, 0...   \n",
       "5  [-0.30424776300405126, -0.04949671606636581, 0...   \n",
       "6  [0.11098324236286285, 0.036409039030220754, -0...   \n",
       "7  [-0.2617804024662385, 0.007203681762336978, 0....   \n",
       "8  [0.06984923510555667, 0.0065180639121361, -0.1...   \n",
       "9  [-0.10305678157119323, -0.04645025593640229, 0...   \n",
       "\n",
       "                                   wor_all_selected1  \n",
       "0  [-0.03628907508059879, -0.028415450913131562, ...  \n",
       "1  [-0.04345398189988287, -0.020184341988825117, ...  \n",
       "2  [-0.2445014187941481, -0.12076884155682255, 0....  \n",
       "3  [-0.1487217599810065, -0.09152232772736152, 0....  \n",
       "4  [-0.06327165709289424, -0.04194209704023101, 0...  \n",
       "5  [-0.04199190272889661, -0.024059956123692574, ...  \n",
       "6  [0.3334432322058594, 0.26953732272642733, -0.2...  \n",
       "7  [0.06378269752602976, 0.008016117756634652, -0...  \n",
       "8  [0.08754686825446154, 0.06462605258728957, -0....  \n",
       "9  [-0.317957439407505, -0.17534088139707735, 0.5...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wor_aggregated.iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Ändra så att varje response cell aggregeras individuellt. Därefter concatineras alla 512 x 8 vectorer\n",
    "#      dimensionerna på vectorn reduceras med en SVD eller PCA. Sen kan de två resulterande dep & wor vectorerna\n",
    "#      läggas in i sina respective dataframes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important variables \n",
    "\n",
    "Deptext = Depression text-response <br> \n",
    "Wortext = Worry text-response\n",
    "\n",
    "dep_all_phraces = Depression all phraces responses <br> \n",
    "wor_all_phraces = Worry all phraces responses\n",
    "\n",
    "dep_all_word = Depression all descriptive word responses <br>\n",
    "wor_all_words = Worry all descriptive word responses\n",
    "\n",
    "dep_all_selected1 = All selected depression word responses <br>\n",
    "wor_all_selected1 = All selected worry word responses\n",
    "\n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "CESDtot = Center for Epidemiological Studies Depression (CESD) <br>\n",
    "PHQtot = PHQ-9 = Patient Helath Questionnaire = a depression scale\n",
    "\n",
    "GADtot = GAD-7 = Generalized anxiety disorder scale <br>\n",
    "PSWQtot = Penn State Worry Questionniare \n",
    "\n",
    "<hr style=\"border:1px solid gray\"> </hr>\n",
    "\n",
    "miniGAD_diagnose = Self-reported MINI (structured interview) GAD diangose <br>\n",
    "minidep_diagnose = Self-reported MINI (structured interview) MDD (depression) diangose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Semantic Representations in Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resp_dep_scale=responses[['minidep_scale']]\n",
    "resp_GAD_scale=responses[['miniGAD_scale']]\n",
    "#Checking for NaN values\n",
    "resp_dep_scale.isnull().values.any() #true\n",
    "resp_GAD_scale.isnull().values.any() #false\n",
    "\n",
    "y_anxiety= resp_GAD_scale.values\n",
    "y_dep=resp_dep_scale.values \n",
    "\n",
    "#Replaceing NaN values with mean value of column - perhaps we should do this differently\n",
    "col_mean = np.nanmean(y_dep, axis=0)\n",
    "col_mean=np.around(col_mean, decimals=0, out=None) #rounding \n",
    "#Find indices that you need to replace\n",
    "inds = np.where(np.isnan(y_dep))\n",
    "#Place column means in the indices. Align the array using take\n",
    "y_dep[inds] = np.take(col_mean, inds[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [975, 976]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-5aa8a62c3300>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#splitting data into training and testing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mX_train_dep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_dep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_dep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_dep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_dep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_dep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2125\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid parameters passed: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2127\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \"\"\"\n\u001b[1;32m    292\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[1;32m    257\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [975, 976]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Semantic-numeric correlations. \n",
    "Analyzing the relationship between semantic responses and a numerical variable\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"Predicting the corresponding numeric rating scales on the basis of these representations by means \n",
    "of multiple linear regression analyses \"\"\"\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "regr = LinearRegression()\n",
    "\n",
    "x_dep = response_space_dep\n",
    "x_anx = response_space_anx\n",
    "#splitting data into training and testing dataset\n",
    "\n",
    "X_train_dep, X_test_dep, y_train_dep, y_test_dep = train_test_split(x_dep, y_dep, test_size=0.2,random_state=0)\n",
    "regr.fit(X_train_dep, y_train_dep) \n",
    "\n",
    "# Predicting the test set results\n",
    "y_pred_dep = regr.predict(X_test_dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"When the predicted variable is categorical, multinomial logistic regression is used.\"\"\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
